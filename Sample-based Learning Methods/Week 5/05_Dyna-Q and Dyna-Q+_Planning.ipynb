{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "sample-based-learning-methods",
      "graded_item_id": "trR7Z",
      "launcher_item_id": "edrCE"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "05_Dyna-Q and Dyna-Q+_Planning.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grvk02/Reinfo_learning/blob/master/Sample-based%20Learning%20Methods/Week%205/05_Dyna-Q%20and%20Dyna-Q%2B_Planning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "346b99c4a9f878e9aec2a07d3ddc08d1",
          "grade": false,
          "grade_id": "cell-be955a21a9add6d6",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "pYK3QsWIAMsd"
      },
      "source": [
        "# Assignment: Dyna-Q and Dyna-Q+"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "ee25bdba2a442f7c9bb323036ff7adff",
          "grade": false,
          "grade_id": "cell-6ab578539f713801",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "rLhWiYjlAMsh"
      },
      "source": [
        "Welcome to this programming assignment! In this notebook, you will:\n",
        "1. implement the Dyna-Q and Dyna-Q+ algorithms. \n",
        "2. compare their performance on an environment which changes to become 'better' than it was before, that is, the task becomes easier. \n",
        "\n",
        "We will give you the environment and infrastructure to run the experiment and visualize the performance. The assignment will be graded automatically by comparing the behavior of your agent to our implementations of the algorithms. The random seed will be set explicitly to avoid different behaviors due to randomness. \n",
        "\n",
        "Please go through the cells in order. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "93057554e87db5c7a4946ae3ba2d5951",
          "grade": false,
          "grade_id": "cell-9da2a3b80d5b1de4",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "UqrvURoPAMsh"
      },
      "source": [
        "## The Shortcut Maze Environment\n",
        "\n",
        "In this maze environment, the goal is to reach the goal state (G) as fast as possible from the starting state (S). There are four actions – up, down, right, left – which take the agent deterministically from a state to the corresponding neighboring states, except when movement is blocked by a wall (denoted by grey) or the edge of the maze, in which case the agent remains where it is. The reward is +1 on reaching the goal state, 0 otherwise. On reaching the goal state G, the agent returns to the start state S to being a new episode. This is a discounted, episodic task with $\\gamma = 0.95$.\n",
        "\n",
        "<img src=\"https://github.com/adithyaprem/Reinforcement-Learning-Specialization/blob/master/Sample-based%20Learning%20Methods/Week%205/shortcut_env.png?raw=1\" alt=\"environment\" width=\"400\"/>\n",
        "\n",
        "Later in the assignment, we will use a variant of this maze in which a 'shortcut' opens up after a certain number of timesteps. We will test if the the Dyna-Q and Dyna-Q+ agents are able to find the newly-opened shorter route to the goal state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "f3979f4d8454c9e24f16ed133d08f086",
          "grade": false,
          "grade_id": "cell-d789ad9af5d734f5",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "zX5WhjCkAMsj"
      },
      "source": [
        "## Packages\n",
        "\n",
        "We import the following libraries that are required for this assignment. Primarily, we shall be using the following libraries:\n",
        "1. numpy: the fundamental package for scientific computing with Python.\n",
        "2. matplotlib: the library for plotting graphs in Python.\n",
        "3. RL-Glue: the library for reinforcement learning experiments.\n",
        "\n",
        "**Please do not import other libraries** — this will break the autograder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBKu2rsMArbD",
        "outputId": "e24ef9c0-c233-46b6-953d-f6328b8cdabb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install jdc"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jdc\n",
            "  Downloading https://files.pythonhosted.org/packages/5a/cb/9afea749985eef20f3160e8826a531c7502e40c35a038dfe49b67726e9a0/jdc-0.0.9-py2.py3-none-any.whl\n",
            "Installing collected packages: jdc\n",
            "Successfully installed jdc-0.0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "f9e9ff5b73bce8269a5d08427e84f998",
          "grade": false,
          "grade_id": "cell-9b59a5e962944c1a",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "hukAqxj-AMsk"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os, jdc, shutil\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from rl_glue import RLGlue\n",
        "from agent import BaseAgent\n",
        "from maze_env import ShortcutMazeEnvironment\n",
        "\n",
        "os.makedirs('results', exist_ok=True)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "2a42e5b7f720fd0165a2b12b4c99f164",
          "grade": false,
          "grade_id": "cell-70ba6356f71f04d6",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "5CKE48ajAMsl"
      },
      "source": [
        "plt.rcParams.update({'font.size': 15})\n",
        "plt.rcParams.update({'figure.figsize': [8,5]})"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "d9b325128e6aa23ac37b7af5193ab516",
          "grade": false,
          "grade_id": "cell-337c52496760f99a",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "SgW_R8QvAMsm"
      },
      "source": [
        "## Section 1: Dyna-Q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "663ef3e7cbb35c2f7bcc99e48697e20c",
          "grade": false,
          "grade_id": "cell-ae016536341366d9",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "swS6H14JAMsm"
      },
      "source": [
        "Let's start with a quick recap of the tabular Dyna-Q algorithm.\n",
        "\n",
        "<div style=\"width:80%\"><img src=\"https://github.com/adithyaprem/Reinforcement-Learning-Specialization/blob/master/Sample-based%20Learning%20Methods/Week%205/images/DynaQ.png?raw=1\" alt=\"DynaQ_pseudocode\"></div>\n",
        "\n",
        "Dyna-Q involves four basic steps:\n",
        "1. Action selection: given an observation, select an action to be performed (here, using the $\\epsilon$-greedy method).\n",
        "2. Direct RL: using the observed next state and reward, update the action values (here, using one-step tabular Q-learning).\n",
        "3. Model learning: using the observed next state and reward, update the model (here, updating a table as the environment is assumed to be deterministic).\n",
        "4. Planning: update the action values by generating $n$ simulated experiences using certain starting states and actions (here, using the random-sample one-step tabular Q-planning method). This is also known as the 'Indirect RL' step. The process of choosing the state and action to simulate an experience with is known as 'search control'.\n",
        "\n",
        "Steps 1 and 2 are parts of the [tabular Q-learning algorithm](http://www.incompleteideas.net/book/RLbook2018.pdf#page=153) and are denoted by line numbers (a)–(d) in the pseudocode above. Step 3 is performed in line (e), and Step 4 in the block of lines (f).\n",
        "\n",
        "We highly recommend revising the Dyna videos in the course and the material in the RL textbook (in particular, [Section 8.2](http://www.incompleteideas.net/book/RLbook2018.pdf#page=183))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "354d65ba93c059d3100345383340a535",
          "grade": false,
          "grade_id": "cell-31575fcfa515756a",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "Qj8mx6xmAMsm"
      },
      "source": [
        "Alright, let's begin coding.\n",
        "\n",
        "As you already know by now, you will develop an agent which interacts with the given environment via RL-Glue. More specifically, you will implement the usual methods `agent_start`, `agent_step`, and `agent_end` in your `DynaQAgent` class, along with a couple of helper methods specific to Dyna-Q, namely `update_model` and `planning_step`. We will provide detailed comments in each method describing what your code should do. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "3aae482d1f386d62c362697ec771bf43",
          "grade": false,
          "grade_id": "cell-85f53bb3ebb9f77d",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "8bA7FYIwAMso"
      },
      "source": [
        "Let's break this down in pieces and do it one-by-one.\n",
        "\n",
        "First of all, check out the `agent_init` method below. As in earlier assignments, some of the attributes are initialized with the data passed inside `agent_info`. In particular, pay attention to the attributes which are new to `DynaQAgent`, since you shall be using them later. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "cb3caf80070a7cce0f65a119522d2dbd",
          "grade": false,
          "grade_id": "cell-eda7a35e5ff3252f",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "_RhW0sASAMsp"
      },
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "class DynaQAgent(BaseAgent):\n",
        "\n",
        "    def agent_init(self, agent_info):\n",
        "        \"\"\"Setup for the agent called when the experiment first starts.\n",
        "\n",
        "        Args:\n",
        "            agent_init_info (dict), the parameters used to initialize the agent. The dictionary contains:\n",
        "            {\n",
        "                num_states (int): The number of states,\n",
        "                num_actions (int): The number of actions,\n",
        "                epsilon (float): The parameter for epsilon-greedy exploration,\n",
        "                step_size (float): The step-size,\n",
        "                discount (float): The discount factor,\n",
        "                planning_steps (int): The number of planning steps per environmental interaction\n",
        "\n",
        "                random_seed (int): the seed for the RNG used in epsilon-greedy\n",
        "                planning_random_seed (int): the seed for the RNG used in the planner\n",
        "            }\n",
        "        \"\"\"\n",
        "\n",
        "        # First, we get the relevant information from agent_info \n",
        "        # NOTE: we use np.random.RandomState(seed) to set the two different RNGs\n",
        "        # for the planner and the rest of the code\n",
        "        try:\n",
        "            self.num_states = agent_info[\"num_states\"]\n",
        "            self.num_actions = agent_info[\"num_actions\"]\n",
        "        except:\n",
        "            print(\"You need to pass both 'num_states' and 'num_actions' \\\n",
        "                   in agent_info to initialize the action-value table\")\n",
        "        self.gamma = agent_info.get(\"discount\", 0.95)\n",
        "        self.step_size = agent_info.get(\"step_size\", 0.1)\n",
        "        self.epsilon = agent_info.get(\"epsilon\", 0.1)\n",
        "        self.planning_steps = agent_info.get(\"planning_steps\", 10)\n",
        "\n",
        "        self.rand_generator = np.random.RandomState(agent_info.get('random_seed', 42))\n",
        "        self.planning_rand_generator = np.random.RandomState(agent_info.get('planning_random_seed', 42))\n",
        "\n",
        "        # Next, we initialize the attributes required by the agent, e.g., q_values, model, etc.\n",
        "        # A simple way to implement the model is to have a dictionary of dictionaries, \n",
        "        #        mapping each state to a dictionary which maps actions to (reward, next state) tuples.\n",
        "        self.q_values = np.zeros((self.num_states, self.num_actions))\n",
        "        self.actions = list(range(self.num_actions))\n",
        "        self.past_action = -1\n",
        "        self.past_state = -1\n",
        "        self.model = {} # model is a dictionary of dictionaries, which maps states to actions to \n",
        "                        # (reward, next_state) tuples"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "c8f49f199eb2c0bf11cba86f0b5d3c6e",
          "grade": false,
          "grade_id": "cell-02a81d97cf066622",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "efGrFuF7AMsp"
      },
      "source": [
        "Now let's create the `update_model` method, which performs the 'Model Update' step in the pseudocode. It takes a `(s, a, s', r)` tuple and stores the next state and reward corresponding to a state-action pair.\n",
        "\n",
        "Remember, because the environment is deterministic, an easy way to implement the model is to have a dictionary of encountered states, each mapping to a dictionary of actions taken in those states, which in turn maps to a tuple of next state and reward. In this way, the model can be easily accessed by `model[s][a]`, which would return the `(s', r)` tuple."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "0623843f71cad67461cc0b5dd7b1751c",
          "grade": false,
          "grade_id": "cell-ca7cf60690bd1e62",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "BEoXCuHUAMsq"
      },
      "source": [
        "%%add_to DynaQAgent\n",
        "\n",
        "# [GRADED]\n",
        "\n",
        "def update_model(self, past_state, past_action, state, reward):\n",
        "    \"\"\"updates the model \n",
        "    \n",
        "    Args:\n",
        "        past_state       (int): s\n",
        "        past_action      (int): a\n",
        "        state            (int): s'\n",
        "        reward           (int): r\n",
        "    Returns:\n",
        "        Nothing\n",
        "    \"\"\"\n",
        "    # Update the model with the (s,a,s',r) tuple (1~4 lines)\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    self.model[past_state] = self.model.get(past_state, {})\n",
        "    self.model[past_state][past_action] = state, reward\n",
        "    ### END CODE HERE ###"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "a67870254bf6049b72911dcbe495ad84",
          "grade": false,
          "grade_id": "cell-feda394cc8d0d0f0",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "HOJ47gcJAMsq"
      },
      "source": [
        "### Test `update_model()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "4f4aeb91268cae5d6169083963dd4460",
          "grade": true,
          "grade_id": "DynaQ_update_model",
          "locked": true,
          "points": 5,
          "schema_version": 1,
          "solution": false
        },
        "id": "jZyv4F3pAMsr",
        "outputId": "b794f646-175c-430e-df54-9f17f62f2f04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "## Test code for update_model() ##\n",
        "\n",
        "actions = []\n",
        "agent_info = {\"num_actions\": 4, \n",
        "              \"num_states\": 3, \n",
        "              \"epsilon\": 0.1, \n",
        "              \"step_size\": 0.1, \n",
        "              \"discount\": 1.0, \n",
        "              \"random_seed\": 0,\n",
        "              \"planning_random_seed\": 0}\n",
        "test_agent = DynaQAgent()\n",
        "test_agent.agent_init(agent_info)\n",
        "test_agent.update_model(0,2,0,1)\n",
        "test_agent.update_model(2,0,1,1)\n",
        "test_agent.update_model(0,3,1,2)\n",
        "print(\"Model: \\n\", test_agent.model)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \n",
            " {0: {2: (0, 1), 3: (1, 2)}, 2: {0: (1, 1)}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "58a644632b6aea7d2850370ab1066b9e",
          "grade": false,
          "grade_id": "cell-47eee79fcc885cb6",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "8d_vy1UZAMsr"
      },
      "source": [
        "Expected output:\n",
        "```\n",
        "Model: \n",
        " {0: {2: (0, 1), 3: (1, 2)}, 2: {0: (1, 1)}}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "b49de532a3a274adce7ebf6169961296",
          "grade": false,
          "grade_id": "cell-21e26a912d8b58f2",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "cVxYUBklAMsr"
      },
      "source": [
        "Next, you will implement the planning step, the crux of the Dyna-Q algorithm. You shall be calling this `planning_step` method at every timestep of every trajectory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "cffbe7372919f7569a283aad349cc76c",
          "grade": false,
          "grade_id": "cell-299f48859b38c670",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "hYp8fI-qAMsr"
      },
      "source": [
        "%%add_to DynaQAgent\n",
        "\n",
        "# [GRADED]\n",
        "\n",
        "def planning_step(self):\n",
        "    \"\"\"performs planning, i.e. indirect RL.\n",
        "\n",
        "    Args:\n",
        "        None\n",
        "    Returns:\n",
        "        Nothing\n",
        "    \"\"\"\n",
        "    \n",
        "    # The indirect RL step:\n",
        "    # - Choose a state and action from the set of experiences that are stored in the model. (~2 lines)\n",
        "    # - Query the model with this state-action pair for the predicted next state and reward.(~1 line)\n",
        "    # - Update the action values with this simulated experience.                            (2~4 lines)\n",
        "    # - Repeat for the required number of planning steps.\n",
        "    #\n",
        "    # Note that the update equation is different for terminal and non-terminal transitions. \n",
        "    # To differentiate between a terminal and a non-terminal next state, assume that the model stores\n",
        "    # the terminal state as a dummy state like -1\n",
        "    #\n",
        "    # Important: remember you have a random number generator 'planning_rand_generator' as \n",
        "    #     a part of the class which you need to use as self.planning_rand_generator.choice()\n",
        "    #     For the sake of reproducibility and grading, *do not* use anything else like \n",
        "    #     np.random.choice() for performing search control.\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    for i in range(self.planning_steps):\n",
        "        past_state = self.planning_rand_generator.choice(list(self.model.keys()))\n",
        "        past_action = self.planning_rand_generator.choice(list(self.model[past_state].keys()))\n",
        "        next_state, reward = self.model[past_state][past_action]\n",
        "        if next_state == -1:\n",
        "            q_max = 0\n",
        "        else:\n",
        "            q_max = np.max(self.q_values[next_state])\n",
        "        self.q_values[past_state, past_action] += self.step_size * (reward + self.gamma * q_max - self.q_values[past_state, past_action])\n",
        "      \n",
        "\n",
        "    ### END CODE HERE ###"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "022cff5daeb2a0885bec5f66231b0233",
          "grade": false,
          "grade_id": "cell-deb5f5adef22b4e0",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "MCSBcgceAMsr"
      },
      "source": [
        "### Test `planning_step()` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "e7b50b6709c1796e9649880aa88b4fcc",
          "grade": true,
          "grade_id": "DynaQ_planning_step",
          "locked": true,
          "points": 5,
          "schema_version": 1,
          "solution": false
        },
        "id": "SAWP6ZTFAMsr",
        "outputId": "13258311-cd95-451b-d5ba-d7a5d57a9598",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "## Test code for planning_step() ##\n",
        "\n",
        "actions = []\n",
        "agent_info = {\"num_actions\": 4, \n",
        "              \"num_states\": 3, \n",
        "              \"epsilon\": 0.1, \n",
        "              \"step_size\": 0.1, \n",
        "              \"discount\": 1.0, \n",
        "              \"planning_steps\": 4,\n",
        "              \"random_seed\": 0,\n",
        "              \"planning_random_seed\": 5}\n",
        "test_agent = DynaQAgent()\n",
        "test_agent.agent_init(agent_info)\n",
        "test_agent.update_model(0,2,1,1)\n",
        "test_agent.update_model(2,0,1,1)\n",
        "test_agent.update_model(0,3,0,1)\n",
        "test_agent.update_model(0,1,-1,1)\n",
        "test_agent.planning_step()\n",
        "print(\"Model: \\n\", test_agent.model)\n",
        "print(\"Action-value estimates: \\n\", test_agent.q_values)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \n",
            " {0: {2: (1, 1), 3: (0, 1), 1: (-1, 1)}, 2: {0: (1, 1)}}\n",
            "Action-value estimates: \n",
            " [[0.  0.1 0.  0.2]\n",
            " [0.  0.  0.  0. ]\n",
            " [0.1 0.  0.  0. ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "cafc07b98a92e3fd29e912aca8a1d2d3",
          "grade": false,
          "grade_id": "cell-2b479d946144873d",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "gUMzc3AyAMss"
      },
      "source": [
        "Expected output:\n",
        "```\n",
        "Model: \n",
        " {0: {2: (1, 1), 3: (0, 1), 1: (-1, 1)}, 2: {0: (1, 1)}}\n",
        "Action-value estimates: \n",
        " [[0.   0.1   0.   0.2 ]\n",
        " [0.   0.   0.   0.  ]\n",
        " [0.1 0.   0.   0.  ]]\n",
        "```\n",
        "\n",
        "If your output does not match the above, one of the first things to check is to make sure that you haven't changed the `planning_random_seed` in the test cell. Additionally, make sure you have handled terminal updates correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "143ef17b6c34ca12c1528346ad7af4d0",
          "grade": false,
          "grade_id": "cell-19299355538e166b",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "hMnSHUa-AMss"
      },
      "source": [
        "Now before you move on to implement the rest of the agent methods, here are the helper functions that you've used in the previous assessments for choosing an action using an $\\epsilon$-greedy policy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "1ab2ef4f11b78d87270f396028252b74",
          "grade": false,
          "grade_id": "cell-9fc1453e5bc78ee0",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "Dj14ljV3AMss"
      },
      "source": [
        "%%add_to DynaQAgent\n",
        "\n",
        "# Do not modify this cell!\n",
        "\n",
        "def argmax(self, q_values):\n",
        "    \"\"\"argmax with random tie-breaking\n",
        "    Args:\n",
        "        q_values (Numpy array): the array of action values\n",
        "    Returns:\n",
        "        action (int): an action with the highest value\n",
        "    \"\"\"\n",
        "    top = float(\"-inf\")\n",
        "    ties = []\n",
        "\n",
        "    for i in range(len(q_values)):\n",
        "        if q_values[i] > top:\n",
        "            top = q_values[i]\n",
        "            ties = []\n",
        "\n",
        "        if q_values[i] == top:\n",
        "            ties.append(i)\n",
        "\n",
        "    return self.rand_generator.choice(ties)\n",
        "\n",
        "def choose_action_egreedy(self, state):\n",
        "    \"\"\"returns an action using an epsilon-greedy policy w.r.t. the current action-value function.\n",
        "\n",
        "    Important: assume you have a random number generator 'rand_generator' as a part of the class\n",
        "                which you can use as self.rand_generator.choice() or self.rand_generator.rand()\n",
        "\n",
        "    Args:\n",
        "        state (List): coordinates of the agent (two elements)\n",
        "    Returns:\n",
        "        The action taken w.r.t. the aforementioned epsilon-greedy policy\n",
        "    \"\"\"\n",
        "\n",
        "    if self.rand_generator.rand() < self.epsilon:\n",
        "        action = self.rand_generator.choice(self.actions)\n",
        "    else:\n",
        "        values = self.q_values[state]\n",
        "        action = self.argmax(values)\n",
        "\n",
        "    return action"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "f836d363c2f53ad316e4d3be6958e543",
          "grade": false,
          "grade_id": "cell-49b0839e77c116f3",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "aE5EyjEbAMst"
      },
      "source": [
        "Next, you will implement the rest of the agent-related methods, namely `agent_start`, `agent_step`, and `agent_end`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "3d5e4eadfae22a3707932558a68f90f2",
          "grade": false,
          "grade_id": "cell-d7cd67287d3a4d59",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "PAoCkrXOAMst"
      },
      "source": [
        "%%add_to DynaQAgent\n",
        "\n",
        "# [GRADED]\n",
        "\n",
        "def agent_start(self, state):\n",
        "    \"\"\"The first method called when the experiment starts, \n",
        "    called after the environment starts.\n",
        "    Args:\n",
        "        state (Numpy array): the state from the\n",
        "            environment's env_start function.\n",
        "    Returns:\n",
        "        (int) the first action the agent takes.\n",
        "    \"\"\"\n",
        "    \n",
        "    # given the state, select the action using self.choose_action_egreedy()), \n",
        "    # and save current state and action (~2 lines)\n",
        "    ### self.past_state = ?\n",
        "    ### self.past_action = ?\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    action= self.choose_action_egreedy(state)\n",
        "    self.past_state=state\n",
        "    self.past_action=action\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return self.past_action\n",
        "\n",
        "def agent_step(self, reward, state):\n",
        "    \"\"\"A step taken by the agent.\n",
        "\n",
        "    Args:\n",
        "        reward (float): the reward received for taking the last action taken\n",
        "        state (Numpy array): the state from the\n",
        "            environment's step based on where the agent ended up after the\n",
        "            last step\n",
        "    Returns:\n",
        "        (int) The action the agent takes given this state.\n",
        "    \"\"\"\n",
        "    \n",
        "    # - Direct-RL step (~1-3 lines)\n",
        "    # - Model Update step (~1 line)\n",
        "    # - `planning_step` (~1 line)\n",
        "    # - Action Selection step (~1 line)\n",
        "    # Save the current state and action before returning the action to be performed. (~2 lines)\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    q_max=np.max(self.q_values[state])\n",
        "    self.q_values[self.past_state, self.past_action] += self.step_size * (reward + self.gamma * q_max - self.q_values[self.past_state, self.past_action])\n",
        "    self.update_model(self.past_state,self.past_action,state,reward)\n",
        "    self.planning_step()\n",
        "    \n",
        "    self.past_state=state\n",
        "    self.past_action=self.choose_action_egreedy(state)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return self.past_action\n",
        "\n",
        "def agent_end(self, reward):\n",
        "    \"\"\"Called when the agent terminates.\n",
        "\n",
        "    Args:\n",
        "        reward (float): the reward the agent received for entering the\n",
        "            terminal state.\n",
        "    \"\"\"\n",
        "    \n",
        "    # - Direct RL update with this final transition (1~2 lines)\n",
        "    # - Model Update step with this final transition (~1 line)\n",
        "    # - One final `planning_step` (~1 line)\n",
        "    #\n",
        "    # Note: the final transition needs to be handled carefully. Since there is no next state, \n",
        "    #       you will have to pass a dummy state (like -1), which you will be using in the planning_step() to \n",
        "    #       differentiate between updates with usual terminal and non-terminal transitions.\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    self.q_values[self.past_state, self.past_action] += self.step_size * (reward - self.q_values[self.past_state, self.past_action])\n",
        "    self.update_model(self.past_state,self.past_action,-1,reward)\n",
        "    self.planning_step()\n",
        "    ### END CODE HERE ###"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "14b7a6eacec0a3564a156c15ed4cc96c",
          "grade": false,
          "grade_id": "cell-cb04070be7e98178",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "WEFRZlyEAMsu"
      },
      "source": [
        "### Test `agent_start()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "241515d8eb09b5d0ca96c1c60a24af07",
          "grade": true,
          "grade_id": "DynaQ_agent_start",
          "locked": true,
          "points": 5,
          "schema_version": 1,
          "solution": false
        },
        "id": "2d5tsrO3AMsu",
        "outputId": "75e7e767-7bf9-4768-e923-546f536417c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "## Test code for agent_start() ##\n",
        "\n",
        "agent_info = {\"num_actions\": 4, \n",
        "              \"num_states\": 3, \n",
        "              \"epsilon\": 0.1, \n",
        "              \"step_size\": 0.1, \n",
        "              \"discount\": 1.0, \n",
        "              \"random_seed\": 0,\n",
        "              \"planning_random_seed\": 0}\n",
        "test_agent = DynaQAgent()\n",
        "test_agent.agent_init(agent_info)\n",
        "action = test_agent.agent_start(0)\n",
        "print(\"Action:\", action)\n",
        "print(\"Model: \\n\", test_agent.model)\n",
        "print(\"Action-value estimates: \\n\", test_agent.q_values)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Action: 1\n",
            "Model: \n",
            " {}\n",
            "Action-value estimates: \n",
            " [[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "f2c06652b1c989ff3174e42a463173ac",
          "grade": false,
          "grade_id": "cell-bc7046affcf9c2f9",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "zev8CbjmAMsu"
      },
      "source": [
        "Expected output:\n",
        "```\n",
        "Action: 1\n",
        "Model: \n",
        " {}\n",
        "Action-value estimates: \n",
        " [[0. 0. 0. 0.]\n",
        " [0. 0. 0. 0.]\n",
        " [0. 0. 0. 0.]]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "b5b76c8ebc0936d8ca8b929d1721fe44",
          "grade": false,
          "grade_id": "cell-069a254ee4ba6e25",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "--n-YaL0AMsu"
      },
      "source": [
        "### Test `agent_step()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "24bf8b0fdf3408e6a36ea968df0c6a36",
          "grade": true,
          "grade_id": "DynaQ__agent_step",
          "locked": true,
          "points": 5,
          "schema_version": 1,
          "solution": false
        },
        "id": "GYgDdE2RAMsv",
        "outputId": "ea567604-d094-44ab-9acd-628f542c1c39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "## Test code for agent_step() ##\n",
        "\n",
        "actions = []\n",
        "agent_info = {\"num_actions\": 4, \n",
        "              \"num_states\": 3, \n",
        "              \"epsilon\": 0.1, \n",
        "              \"step_size\": 0.1, \n",
        "              \"discount\": 1.0, \n",
        "              \"planning_steps\": 2,\n",
        "              \"random_seed\": 0,\n",
        "              \"planning_random_seed\": 0}\n",
        "test_agent = DynaQAgent()\n",
        "test_agent.agent_init(agent_info)\n",
        "actions.append(test_agent.agent_start(0))\n",
        "actions.append(test_agent.agent_step(1,2))\n",
        "actions.append(test_agent.agent_step(0,1))\n",
        "print(\"Actions:\", actions)\n",
        "print(\"Model: \\n\", test_agent.model)\n",
        "print(\"Action-value estimates: \\n\", test_agent.q_values)\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actions: [1, 3, 1]\n",
            "Model: \n",
            " {0: {1: (2, 1)}, 2: {3: (1, 0)}}\n",
            "Action-value estimates: \n",
            " [[0.     0.3439 0.     0.    ]\n",
            " [0.     0.     0.     0.    ]\n",
            " [0.     0.     0.     0.    ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "a47eae38f5b82056b69ea71037a76465",
          "grade": false,
          "grade_id": "cell-0b8605acd440fc7d",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "I_Ap9ymaAMsv"
      },
      "source": [
        "Expected output:\n",
        "\n",
        "```\n",
        "Actions: [1, 3, 1]\n",
        "Model: \n",
        " {0: {1: (2, 1)}, 2: {3: (1, 0)}}\n",
        "Action-value estimates: \n",
        " [[0.     0.3439 0.     0.    ]\n",
        " [0.     0.     0.     0.    ]\n",
        " [0.     0.     0.     0.    ]]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "c1fee78afea91645becfd5b193b4b9ab",
          "grade": false,
          "grade_id": "cell-8d3e06f7f489a49c",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "g6WiYGsQAMsv"
      },
      "source": [
        "### Test `agent_end()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "b8e64a1aa1ab9917e78149b1ab4fc9e8",
          "grade": true,
          "grade_id": "DynaQ_agent_end",
          "locked": true,
          "points": 5,
          "schema_version": 1,
          "solution": false
        },
        "id": "Ya6uaLZpAMsv",
        "outputId": "cccda7a9-20dd-46ba-9cfd-bf6bd424918a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "## Test code for agent_end() ##\n",
        "\n",
        "actions = []\n",
        "agent_info = {\"num_actions\": 4, \n",
        "              \"num_states\": 3, \n",
        "              \"epsilon\": 0.1, \n",
        "              \"step_size\": 0.1, \n",
        "              \"discount\": 1.0, \n",
        "              \"planning_steps\": 2,\n",
        "              \"random_seed\": 0,\n",
        "              \"planning_random_seed\": 0}\n",
        "test_agent = DynaQAgent()\n",
        "test_agent.agent_init(agent_info)\n",
        "actions.append(test_agent.agent_start(0))\n",
        "actions.append(test_agent.agent_step(1,2))\n",
        "actions.append(test_agent.agent_step(0,1))\n",
        "test_agent.agent_end(1)\n",
        "print(\"Actions:\", actions)\n",
        "print(\"Model: \\n\", test_agent.model)\n",
        "print(\"Action-value Estimates: \\n\", test_agent.q_values)\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actions: [1, 3, 1]\n",
            "Model: \n",
            " {0: {1: (2, 1)}, 2: {3: (1, 0)}, 1: {1: (-1, 1)}}\n",
            "Action-value Estimates: \n",
            " [[0.      0.41051 0.      0.     ]\n",
            " [0.      0.1     0.      0.     ]\n",
            " [0.      0.      0.      0.01   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "43711ecd45a75f4ee1f31ac3f5127477",
          "grade": false,
          "grade_id": "cell-25bdfd8dc303b1e7",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "S2u6jyD2AMsx"
      },
      "source": [
        "Expected output:\n",
        "\n",
        "```\n",
        "Actions: [1, 3, 1]\n",
        "Model: \n",
        " {0: {1: (2, 1)}, 2: {3: (1, 0)}, 1: {1: (-1, 1)}}\n",
        "Action-value Estimates: \n",
        " [[0.      0.41051 0.      0.     ]\n",
        " [0.      0.1     0.      0.     ]\n",
        " [0.      0.      0.      0.01   ]]\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "12f59fa0e03a4b5df596a73e3dae0c02",
          "grade": false,
          "grade_id": "cell-329423dc3230312d",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "MO1NuLW0AMsx"
      },
      "source": [
        "### Experiment: Dyna-Q agent in the maze environment\n",
        "\n",
        "Alright. Now we have all the components of the `DynaQAgent` ready. Let's try it out on the maze environment! \n",
        "\n",
        "The next cell runs an experiment on this maze environment to test your implementation. The initial action values are $0$, the step-size parameter is $0.125$. and the exploration parameter is $\\epsilon=0.1$. After the experiment, the sum of rewards in each episode should match the correct result.\n",
        "\n",
        "We will try planning steps of $0,5,50$ and compare their performance in terms of the average number of steps taken to reach the goal state in the aforementioned maze environment. For scientific rigor, we will run each experiment $30$ times. In each experiment, we set the initial random-number-generator (RNG) seeds for a fair comparison across algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "a2573b31bd8cce3a89beba2ec09ab2c3",
          "grade": false,
          "grade_id": "cell-28355ff7447c705f",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "raP4jO2dAMsx"
      },
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "def run_experiment(env, agent, env_parameters, agent_parameters, exp_parameters):\n",
        "\n",
        "    # Experiment settings\n",
        "    num_runs = exp_parameters['num_runs']\n",
        "    num_episodes = exp_parameters['num_episodes']\n",
        "    planning_steps_all = agent_parameters['planning_steps']\n",
        "\n",
        "    env_info = env_parameters                     \n",
        "    agent_info = {\"num_states\" : agent_parameters[\"num_states\"],  # We pass the agent the information it needs. \n",
        "                  \"num_actions\" : agent_parameters[\"num_actions\"],\n",
        "                  \"epsilon\": agent_parameters[\"epsilon\"], \n",
        "                  \"discount\": env_parameters[\"discount\"],\n",
        "                  \"step_size\" : agent_parameters[\"step_size\"]}\n",
        "\n",
        "    all_averages = np.zeros((len(planning_steps_all), num_runs, num_episodes)) # for collecting metrics \n",
        "    log_data = {'planning_steps_all' : planning_steps_all}                     # that shall be plotted later\n",
        "\n",
        "    for idx, planning_steps in enumerate(planning_steps_all):\n",
        "\n",
        "        print('Planning steps : ', planning_steps)\n",
        "        os.system('sleep 0.5')                    # to prevent tqdm printing out-of-order before the above print()\n",
        "        agent_info[\"planning_steps\"] = planning_steps  \n",
        "\n",
        "        for i in tqdm(range(num_runs)):\n",
        "\n",
        "            agent_info['random_seed'] = i\n",
        "            agent_info['planning_random_seed'] = i\n",
        "\n",
        "            rl_glue = RLGlue(env, agent)          # Creates a new RLGlue experiment with the env and agent we chose above\n",
        "            rl_glue.rl_init(agent_info, env_info) # We pass RLGlue what it needs to initialize the agent and environment\n",
        "\n",
        "            for j in range(num_episodes):\n",
        "\n",
        "                rl_glue.rl_start()                # We start an episode. Here we aren't using rl_glue.rl_episode()\n",
        "                                                  # like the other assessments because we'll be requiring some \n",
        "                is_terminal = False               # data from within the episodes in some of the experiments here \n",
        "                num_steps = 0\n",
        "                while not is_terminal:\n",
        "                    reward, _, action, is_terminal = rl_glue.rl_step()  # The environment and agent take a step \n",
        "                    num_steps += 1                                      # and return the reward and action taken.\n",
        "\n",
        "                all_averages[idx][i][j] = num_steps\n",
        "\n",
        "    log_data['all_averages'] = all_averages\n",
        "    np.save(\"results/Dyna-Q_planning_steps\", log_data)\n",
        "    \n",
        "\n",
        "def plot_steps_per_episode(file_path):\n",
        "\n",
        "    data = np.load(file_path,allow_pickle=True).item()\n",
        "    all_averages = data['all_averages']\n",
        "    planning_steps_all = data['planning_steps_all']\n",
        "\n",
        "    for i, planning_steps in enumerate(planning_steps_all):\n",
        "        plt.plot(np.mean(all_averages[i], axis=0), label='Planning steps = '+str(planning_steps))\n",
        "\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.xlabel('Episodes')\n",
        "    plt.ylabel('Steps\\nper\\nepisode', rotation=0, labelpad=40)\n",
        "    plt.axhline(y=16, linestyle='--', color='grey', alpha=0.4)\n",
        "    plt.show()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgCKW2bWAMsx",
        "outputId": "14c47390-5169-4689-9d75-6da4dce14e99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "# Do NOT modify the parameter settings.\n",
        "\n",
        "# Experiment parameters\n",
        "experiment_parameters = {\n",
        "    \"num_runs\" : 30,                     # The number of times we run the experiment\n",
        "    \"num_episodes\" : 40,                 # The number of episodes per experiment\n",
        "}\n",
        "\n",
        "# Environment parameters\n",
        "environment_parameters = { \n",
        "    \"discount\": 0.95,\n",
        "}\n",
        "\n",
        "# Agent parameters\n",
        "agent_parameters = {  \n",
        "    \"num_states\" : 54,\n",
        "    \"num_actions\" : 4, \n",
        "    \"epsilon\": 0.1, \n",
        "    \"step_size\" : 0.125,\n",
        "    \"planning_steps\" : [0, 5, 50]       # The list of planning_steps we want to try\n",
        "}\n",
        "\n",
        "current_env = ShortcutMazeEnvironment   # The environment\n",
        "current_agent = DynaQAgent              # The agent\n",
        "\n",
        "run_experiment(current_env, current_agent, environment_parameters, agent_parameters, experiment_parameters)\n",
        "plot_steps_per_episode('results/Dyna-Q_planning_steps.npy')   \n",
        "shutil.make_archive('results', 'zip', 'results');"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Planning steps :  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:10<00:00,  2.78it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Planning steps :  5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:12<00:00,  2.35it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Planning steps :  50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [01:31<00:00,  3.04s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "b78255378e333ad6a4b69eadb1c5bce9",
          "grade": false,
          "grade_id": "cell-e55bf393c9e5a94b",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "1KksxmzTAMsx"
      },
      "source": [
        "What do you notice?\n",
        "\n",
        "As the number of planning steps increases, the number of episodes taken to reach the goal decreases rapidly. Remember that the RNG seed was set the same for all the three values of planning steps, resulting in the same number of steps taken to reach the goal in the first episode. Thereafter, the performance improves. The slowest improvement is when there are $n=0$ planning steps, i.e., for the non-planning Q-learning agent, even though the step size parameter was optimized for it. Note that the grey dotted line shows the minimum number of steps required to reach the goal state under the optimal greedy policy.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "38982e501241998792ae2aebe105c47b",
          "grade": false,
          "grade_id": "cell-56f6a9492acc5115",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "Gi-m6icaAMsy"
      },
      "source": [
        "### Experiment(s): Dyna-Q agent in the _changing_ maze environment "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "28e53909e26c756c30000e1a0f0d9b4c",
          "grade": false,
          "grade_id": "cell-64cbd79abcf74fce",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "6vxpDoXeAMsy"
      },
      "source": [
        "Great! Now let us see how Dyna-Q performs on the version of the maze in which a shorter path opens up after 3000 steps. The rest of the transition and reward dynamics remain the same. \n",
        "\n",
        "<img src=\"https://github.com/adithyaprem/Reinforcement-Learning-Specialization/blob/master/Sample-based%20Learning%20Methods/Week%205/images/shortcut_env_after.png?raw=1\" alt=\"environment\" width=\"800\"/>\n",
        "\n",
        "Before you proceed, take a moment to think about what you expect to see. Will Dyna-Q find the new, shorter path to the goal? If so, why? If not, why not?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "fd85c37c0082135d539e4160d4e07949",
          "grade": false,
          "grade_id": "cell-8f6730285bc8288e",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "g283uNxGAMsy"
      },
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "def run_experiment_with_state_visitations(env, agent, env_parameters, agent_parameters, exp_parameters, result_file_name):\n",
        "\n",
        "    # Experiment settings\n",
        "    num_runs = exp_parameters['num_runs']\n",
        "    num_max_steps = exp_parameters['num_max_steps']\n",
        "    planning_steps_all = agent_parameters['planning_steps']\n",
        "\n",
        "    env_info = {\"change_at_n\" : env_parameters[\"change_at_n\"]}                     \n",
        "    agent_info = {\"num_states\" : agent_parameters[\"num_states\"],  \n",
        "                  \"num_actions\" : agent_parameters[\"num_actions\"],\n",
        "                  \"epsilon\": agent_parameters[\"epsilon\"], \n",
        "                  \"discount\": env_parameters[\"discount\"],\n",
        "                  \"step_size\" : agent_parameters[\"step_size\"]}\n",
        "\n",
        "    state_visits_before_change = np.zeros((len(planning_steps_all), num_runs, 54))  # For saving the number of\n",
        "    state_visits_after_change = np.zeros((len(planning_steps_all), num_runs, 54))   #     state-visitations \n",
        "    cum_reward_all = np.zeros((len(planning_steps_all), num_runs, num_max_steps))   # For saving the cumulative reward\n",
        "    log_data = {'planning_steps_all' : planning_steps_all}\n",
        "\n",
        "    for idx, planning_steps in enumerate(planning_steps_all):\n",
        "\n",
        "        print('Planning steps : ', planning_steps)\n",
        "        os.system('sleep 1')          # to prevent tqdm printing out-of-order before the above print()\n",
        "        agent_info[\"planning_steps\"] = planning_steps  # We pass the agent the information it needs. \n",
        "\n",
        "        for run in tqdm(range(num_runs)):\n",
        "\n",
        "            agent_info['random_seed'] = run\n",
        "            agent_info['planning_random_seed'] = run\n",
        "\n",
        "            rl_glue = RLGlue(env, agent)  # Creates a new RLGlue experiment with the env and agent we chose above\n",
        "            rl_glue.rl_init(agent_info, env_info) # We pass RLGlue what it needs to initialize the agent and environment\n",
        "\n",
        "            num_steps = 0\n",
        "            cum_reward = 0\n",
        "\n",
        "            while num_steps < num_max_steps-1 :\n",
        "\n",
        "                state, _ = rl_glue.rl_start()  # We start the experiment. We'll be collecting the \n",
        "                is_terminal = False            # state-visitation counts to visiualize the learned policy\n",
        "                if num_steps < env_parameters[\"change_at_n\"]: \n",
        "                    state_visits_before_change[idx][run][state] += 1\n",
        "                else:\n",
        "                    state_visits_after_change[idx][run][state] += 1\n",
        "\n",
        "                while not is_terminal and num_steps < num_max_steps-1 :\n",
        "                    reward, state, action, is_terminal = rl_glue.rl_step()  \n",
        "                    num_steps += 1\n",
        "                    cum_reward += reward\n",
        "                    cum_reward_all[idx][run][num_steps] = cum_reward\n",
        "                    if num_steps < env_parameters[\"change_at_n\"]:\n",
        "                        state_visits_before_change[idx][run][state] += 1\n",
        "                    else:\n",
        "                        state_visits_after_change[idx][run][state] += 1\n",
        "\n",
        "    log_data['state_visits_before'] = state_visits_before_change\n",
        "    log_data['state_visits_after'] = state_visits_after_change\n",
        "    log_data['cum_reward_all'] = cum_reward_all\n",
        "    np.save(\"results/\" + result_file_name, log_data)\n",
        "\n",
        "def plot_cumulative_reward(file_path, item_key, y_key, y_axis_label, legend_prefix, title):\n",
        "\n",
        "    data_all = np.load(file_path,allow_pickle=True).item()\n",
        "    data_y_all = data_all[y_key]\n",
        "    items = data_all[item_key]\n",
        "\n",
        "    for i, item in enumerate(items):\n",
        "        plt.plot(np.mean(data_y_all[i], axis=0), label=legend_prefix+str(item))\n",
        "\n",
        "    plt.axvline(x=3000, linestyle='--', color='grey', alpha=0.4)\n",
        "    plt.xlabel('Timesteps')\n",
        "    plt.ylabel(y_axis_label, rotation=0, labelpad=60)\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "e463255ee451c8ca255ed3f24dd96bf4",
          "grade": false,
          "grade_id": "cell-7a4965729e7c41f3",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "l3829Ka3AMsz"
      },
      "source": [
        "Did you notice that the environment changes after a fixed number of _steps_ and not episodes? \n",
        "\n",
        "This is because the environment is separate from the agent, and the environment changes irrespective of the length of each episode (i.e., the number of environmental interactions per episode) that the agent perceives. And hence we are now plotting the data per step or interaction of the agent and the environment, in order to comfortably see the differences in the behaviours of the agents before and after the environment changes.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "e5a10d7810edcc38ed364530e320e5b7",
          "grade": false,
          "grade_id": "cell-1585cb7119e3b66d",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "6W_pJEvFAMsz"
      },
      "source": [
        "Okay, now we will first plot the cumulative reward obtained by the agent per interaction with the environment, averaged over 10 runs of the experiment on this changing world. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li7aQS6LAMsz",
        "outputId": "cc475dc3-c04a-4b39-8ee6-297e4780032d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        }
      },
      "source": [
        "# Do NOT modify the parameter settings.\n",
        "\n",
        "# Experiment parameters\n",
        "experiment_parameters = {\n",
        "    \"num_runs\" : 10,                     # The number of times we run the experiment\n",
        "    \"num_max_steps\" : 6000,              # The number of steps per experiment\n",
        "}\n",
        "\n",
        "# Environment parameters\n",
        "environment_parameters = { \n",
        "    \"discount\": 0.95,\n",
        "    \"change_at_n\": 3000\n",
        "}\n",
        "\n",
        "# Agent parameters\n",
        "agent_parameters = {  \n",
        "    \"num_states\" : 54,\n",
        "    \"num_actions\" : 4, \n",
        "    \"epsilon\": 0.1, \n",
        "    \"step_size\" : 0.125,\n",
        "    \"planning_steps\" : [5, 10, 50]      # The list of planning_steps we want to try\n",
        "}\n",
        "\n",
        "current_env = ShortcutMazeEnvironment   # The environment\n",
        "current_agent = DynaQAgent              # The agent\n",
        "\n",
        "run_experiment_with_state_visitations(current_env, current_agent, environment_parameters, agent_parameters, experiment_parameters, \"Dyna-Q_shortcut_steps\")    \n",
        "plot_cumulative_reward('results/Dyna-Q_shortcut_steps.npy', 'planning_steps_all', 'cum_reward_all', 'Cumulative\\nreward', 'Planning steps = ', 'Dyna-Q : Varying planning_steps')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Planning steps :  5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|█         | 1/10 [00:01<00:14,  1.57s/it]\u001b[A\n",
            " 20%|██        | 2/10 [00:03<00:12,  1.54s/it]\u001b[A\n",
            " 30%|███       | 3/10 [00:04<00:10,  1.57s/it]\u001b[A\n",
            " 40%|████      | 4/10 [00:06<00:09,  1.51s/it]\u001b[A\n",
            " 50%|█████     | 5/10 [00:07<00:07,  1.50s/it]\u001b[A\n",
            " 60%|██████    | 6/10 [00:09<00:06,  1.53s/it]\u001b[A\n",
            " 70%|███████   | 7/10 [00:10<00:04,  1.49s/it]\u001b[A\n",
            " 80%|████████  | 8/10 [00:11<00:02,  1.47s/it]\u001b[A\n",
            " 90%|█████████ | 9/10 [00:13<00:01,  1.43s/it]\u001b[A\n",
            "100%|██████████| 10/10 [00:14<00:00,  1.45s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Planning steps :  10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|█         | 1/10 [00:03<00:27,  3.00s/it]\u001b[A\n",
            " 20%|██        | 2/10 [00:06<00:24,  3.02s/it]\u001b[A\n",
            " 30%|███       | 3/10 [00:08<00:20,  2.96s/it]\u001b[A\n",
            " 40%|████      | 4/10 [00:11<00:16,  2.80s/it]\u001b[A\n",
            " 50%|█████     | 5/10 [00:14<00:13,  2.78s/it]\u001b[A\n",
            " 60%|██████    | 6/10 [00:16<00:10,  2.73s/it]\u001b[A\n",
            " 70%|███████   | 7/10 [00:19<00:08,  2.72s/it]\u001b[A\n",
            " 80%|████████  | 8/10 [00:21<00:05,  2.64s/it]\u001b[A\n",
            " 90%|█████████ | 9/10 [00:24<00:02,  2.64s/it]\u001b[A\n",
            "100%|██████████| 10/10 [00:27<00:00,  2.71s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Planning steps :  50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|█         | 1/10 [00:13<01:57, 13.05s/it]\u001b[A\n",
            " 20%|██        | 2/10 [00:23<01:37, 12.22s/it]\u001b[A\n",
            " 30%|███       | 3/10 [00:35<01:25, 12.17s/it]\u001b[A\n",
            " 40%|████      | 4/10 [00:47<01:13, 12.28s/it]\u001b[A\n",
            " 50%|█████     | 5/10 [01:00<01:01, 12.25s/it]\u001b[A\n",
            " 60%|██████    | 6/10 [01:12<00:49, 12.44s/it]\u001b[A\n",
            " 70%|███████   | 7/10 [01:25<00:37, 12.38s/it]\u001b[A\n",
            " 80%|████████  | 8/10 [01:37<00:24, 12.24s/it]\u001b[A\n",
            " 90%|█████████ | 9/10 [01:48<00:12, 12.06s/it]\u001b[A\n",
            "100%|██████████| 10/10 [02:01<00:00, 12.18s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "2ce0809c6896af47bf2391c654533a42",
          "grade": false,
          "grade_id": "cell-bdab2f4622d3890b",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "0xpUaQZJAMs0"
      },
      "source": [
        "We observe that the slope of the curves is almost constant. If the agent had discovered the shortcut and begun using it, we would expect to see an increase in the slope of the curves towards the later stages of training. This is because the agent can get to the goal state faster and get the positive reward. Note that the timestep at which the shortcut opens up is marked by the grey dotted line.\n",
        "\n",
        "Note that this trend is constant across the increasing number of planning steps.\n",
        "\n",
        "Now let's check the heatmap of the state visitations of the agent with `planning_steps=10` during training, before and after the shortcut opens up after 3000 timesteps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "2ebb3b3a6fa7c60ee1f35412d3b35e74",
          "grade": false,
          "grade_id": "cell-36a0d9e197e4f128",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "oLq2nnvHAMs0"
      },
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "def plot_state_visitations(file_path, plot_titles, idx):\n",
        "\n",
        "    data = np.load(file_path,allow_pickle=True).item()\n",
        "    data_keys = [\"state_visits_before\", \"state_visits_after\"]\n",
        "    positions = [211,212]\n",
        "    titles = plot_titles\n",
        "    wall_ends = [None,-1]\n",
        "\n",
        "    for i in range(2):\n",
        "\n",
        "        state_visits = data[data_keys[i]][idx]\n",
        "        average_state_visits = np.mean(state_visits, axis=0)\n",
        "        grid_state_visits = np.rot90(average_state_visits.reshape((6,9)).T)\n",
        "        grid_state_visits[2,1:wall_ends[i]] = np.nan # walls\n",
        "        #print(average_state_visits.reshape((6,9)))\n",
        "        plt.subplot(positions[i])\n",
        "        plt.pcolormesh(grid_state_visits, edgecolors='gray', linewidth=1, cmap='viridis')\n",
        "        plt.text(3+0.5, 0+0.5, 'S', horizontalalignment='center', verticalalignment='center')\n",
        "        plt.text(8+0.5, 5+0.5, 'G', horizontalalignment='center', verticalalignment='center')\n",
        "        plt.title(titles[i])\n",
        "        plt.axis('off')\n",
        "        cm = plt.get_cmap()\n",
        "        cm.set_bad('gray')\n",
        "\n",
        "    plt.subplots_adjust(bottom=0.0, right=0.7, top=1.0)\n",
        "    cax = plt.axes([1., 0.0, 0.075, 1.])\n",
        "    cbar = plt.colorbar(cax=cax)\n",
        "    plt.show()"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsALKAAoAMs1",
        "outputId": "c8e5299d-e64b-424b-9b59-9ba89f664efc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "plot_state_visitations(\"results/Dyna-Q_shortcut_steps.npy\", ['Dyna-Q : State visitations before the env changes', 'Dyna-Q : State visitations after the env changes'], 1)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "15aded4269ccf83bd3fa9b4ca9be353c",
          "grade": false,
          "grade_id": "cell-61bd2cfdba9cc49d",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "z8lT3e92AMs1"
      },
      "source": [
        "What do you observe?\n",
        "\n",
        "The state visitation map looks almost the same before and after the shortcut opens. This means that the Dyna-Q agent hasn't quite discovered and started exploiting the new shortcut.\n",
        "\n",
        "Now let's try increasing the exploration parameter $\\epsilon$ to see if it helps the Dyna-Q agent discover the shortcut. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "c97f95a59de3b9000e564c23dd1e8a6e",
          "grade": false,
          "grade_id": "cell-c9eab4ed4cf50870",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "m_kEfczfAMs1"
      },
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "def run_experiment_only_cumulative_reward(env, agent, env_parameters, agent_parameters, exp_parameters):\n",
        "\n",
        "    # Experiment settings\n",
        "    num_runs = exp_parameters['num_runs']\n",
        "    num_max_steps = exp_parameters['num_max_steps']\n",
        "    epsilons = agent_parameters['epsilons']\n",
        "\n",
        "    env_info = {\"change_at_n\" : env_parameters[\"change_at_n\"]}                     \n",
        "    agent_info = {\"num_states\" : agent_parameters[\"num_states\"],  \n",
        "                  \"num_actions\" : agent_parameters[\"num_actions\"],\n",
        "                  \"planning_steps\": agent_parameters[\"planning_steps\"], \n",
        "                  \"discount\": env_parameters[\"discount\"],\n",
        "                  \"step_size\" : agent_parameters[\"step_size\"]}\n",
        "\n",
        "    log_data = {'epsilons' : epsilons} \n",
        "    cum_reward_all = np.zeros((len(epsilons), num_runs, num_max_steps))\n",
        "\n",
        "    for eps_idx, epsilon in enumerate(epsilons):\n",
        "\n",
        "        print('Agent : Dyna-Q, epsilon : %f' % epsilon)\n",
        "        os.system('sleep 1')          # to prevent tqdm printing out-of-order before the above print()\n",
        "        agent_info[\"epsilon\"] = epsilon\n",
        "\n",
        "        for run in tqdm(range(num_runs)):\n",
        "\n",
        "            agent_info['random_seed'] = run\n",
        "            agent_info['planning_random_seed'] = run\n",
        "\n",
        "            rl_glue = RLGlue(env, agent)  # Creates a new RLGlue experiment with the env and agent we chose above\n",
        "            rl_glue.rl_init(agent_info, env_info) # We pass RLGlue what it needs to initialize the agent and environment\n",
        "\n",
        "            num_steps = 0\n",
        "            cum_reward = 0\n",
        "\n",
        "            while num_steps < num_max_steps-1 :\n",
        "\n",
        "                rl_glue.rl_start()  # We start the experiment\n",
        "                is_terminal = False\n",
        "\n",
        "                while not is_terminal and num_steps < num_max_steps-1 :\n",
        "                    reward, _, action, is_terminal = rl_glue.rl_step()  # The environment and agent take a step and return\n",
        "                    # the reward, and action taken.\n",
        "                    num_steps += 1\n",
        "                    cum_reward += reward\n",
        "                    cum_reward_all[eps_idx][run][num_steps] = cum_reward\n",
        "\n",
        "    log_data['cum_reward_all'] = cum_reward_all\n",
        "    np.save(\"results/Dyna-Q_epsilons\", log_data)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW04kKp-AMs2",
        "outputId": "1d4a6d49-b76a-491f-b0f1-76da5212c499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Do NOT modify the parameter settings.\n",
        "\n",
        "# Experiment parameters\n",
        "experiment_parameters = {\n",
        "    \"num_runs\" : 30,                     # The number of times we run the experiment\n",
        "    \"num_max_steps\" : 6000,              # The number of steps per experiment\n",
        "}\n",
        "\n",
        "# Environment parameters\n",
        "environment_parameters = { \n",
        "    \"discount\": 0.95,\n",
        "    \"change_at_n\": 3000\n",
        "}\n",
        "\n",
        "# Agent parameters\n",
        "agent_parameters = {  \n",
        "    \"num_states\" : 54,\n",
        "    \"num_actions\" : 4, \n",
        "    \"step_size\" : 0.125,\n",
        "    \"planning_steps\" : 10,\n",
        "    \"epsilons\": [0.1, 0.2, 0.4, 0.8]    # The list of epsilons we want to try\n",
        "}\n",
        "\n",
        "current_env = ShortcutMazeEnvironment   # The environment\n",
        "current_agent = DynaQAgent              # The agent\n",
        "\n",
        "run_experiment_only_cumulative_reward(current_env, current_agent, environment_parameters, agent_parameters, experiment_parameters)\n",
        "plot_cumulative_reward('results/Dyna-Q_epsilons.npy', 'epsilons', 'cum_reward_all', 'Cumulative\\nreward', r'$\\epsilon$ = ', r'Dyna-Q : Varying $\\epsilon$')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Agent : Dyna-Q, epsilon : 0.100000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
            "  3%|▎         | 1/30 [00:03<01:27,  3.02s/it]\u001b[A\n",
            "  7%|▋         | 2/30 [00:05<01:18,  2.80s/it]\u001b[A\n",
            " 10%|█         | 3/30 [00:08<01:18,  2.90s/it]\u001b[A\n",
            " 13%|█▎        | 4/30 [00:11<01:13,  2.82s/it]\u001b[A\n",
            " 17%|█▋        | 5/30 [00:13<01:11,  2.84s/it]\u001b[A\n",
            " 20%|██        | 6/30 [00:16<01:07,  2.81s/it]\u001b[A\n",
            " 23%|██▎       | 7/30 [00:19<01:03,  2.75s/it]\u001b[A\n",
            " 27%|██▋       | 8/30 [00:22<01:02,  2.82s/it]\u001b[A\n",
            " 30%|███       | 9/30 [00:24<00:57,  2.72s/it]\u001b[A\n",
            " 33%|███▎      | 10/30 [00:27<00:55,  2.76s/it]\u001b[A\n",
            " 37%|███▋      | 11/30 [00:30<00:52,  2.76s/it]\u001b[A\n",
            " 40%|████      | 12/30 [00:33<00:49,  2.76s/it]\u001b[A\n",
            " 43%|████▎     | 13/30 [00:36<00:49,  2.90s/it]\u001b[A\n",
            " 47%|████▋     | 14/30 [00:39<00:47,  2.96s/it]\u001b[A\n",
            " 50%|█████     | 15/30 [00:42<00:44,  2.98s/it]\u001b[A\n",
            " 53%|█████▎    | 16/30 [00:44<00:39,  2.83s/it]\u001b[A\n",
            " 57%|█████▋    | 17/30 [00:47<00:35,  2.73s/it]\u001b[A\n",
            " 60%|██████    | 18/30 [00:49<00:31,  2.63s/it]\u001b[A\n",
            " 63%|██████▎   | 19/30 [00:52<00:27,  2.50s/it]\u001b[A\n",
            " 67%|██████▋   | 20/30 [00:54<00:25,  2.59s/it]\u001b[A\n",
            " 70%|███████   | 21/30 [00:57<00:24,  2.70s/it]\u001b[A\n",
            " 73%|███████▎  | 22/30 [01:00<00:21,  2.70s/it]\u001b[A\n",
            " 77%|███████▋  | 23/30 [01:02<00:18,  2.60s/it]\u001b[A\n",
            " 80%|████████  | 24/30 [01:05<00:15,  2.57s/it]\u001b[A\n",
            " 83%|████████▎ | 25/30 [01:08<00:13,  2.77s/it]\u001b[A\n",
            " 87%|████████▋ | 26/30 [01:11<00:11,  2.90s/it]\u001b[A\n",
            " 90%|█████████ | 27/30 [01:14<00:08,  2.89s/it]\u001b[A\n",
            " 93%|█████████▎| 28/30 [01:17<00:05,  2.87s/it]\u001b[A\n",
            " 97%|█████████▋| 29/30 [01:20<00:02,  2.96s/it]\u001b[A\n",
            "100%|██████████| 30/30 [01:23<00:00,  2.78s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Agent : Dyna-Q, epsilon : 0.200000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
            "  3%|▎         | 1/30 [00:02<01:18,  2.72s/it]\u001b[A\n",
            "  7%|▋         | 2/30 [00:05<01:17,  2.75s/it]\u001b[A\n",
            " 10%|█         | 3/30 [00:08<01:17,  2.85s/it]\u001b[A\n",
            " 13%|█▎        | 4/30 [00:11<01:15,  2.92s/it]\u001b[A\n",
            " 17%|█▋        | 5/30 [00:14<01:09,  2.79s/it]\u001b[A\n",
            " 20%|██        | 6/30 [00:17<01:10,  2.94s/it]\u001b[A\n",
            " 23%|██▎       | 7/30 [00:20<01:06,  2.91s/it]\u001b[A\n",
            " 27%|██▋       | 8/30 [00:23<01:02,  2.86s/it]\u001b[A\n",
            " 30%|███       | 9/30 [00:25<00:59,  2.81s/it]\u001b[A\n",
            " 33%|███▎      | 10/30 [00:28<00:55,  2.77s/it]\u001b[A\n",
            " 37%|███▋      | 11/30 [00:31<00:51,  2.71s/it]\u001b[A\n",
            " 40%|████      | 12/30 [00:34<00:50,  2.79s/it]\u001b[A\n",
            " 43%|████▎     | 13/30 [00:36<00:45,  2.67s/it]\u001b[A\n",
            " 47%|████▋     | 14/30 [00:39<00:42,  2.67s/it]\u001b[A\n",
            " 50%|█████     | 15/30 [00:41<00:40,  2.67s/it]\u001b[A\n",
            " 53%|█████▎    | 16/30 [00:44<00:38,  2.72s/it]\u001b[A\n",
            " 57%|█████▋    | 17/30 [00:47<00:35,  2.74s/it]\u001b[A\n",
            " 60%|██████    | 18/30 [00:50<00:33,  2.80s/it]\u001b[A\n",
            " 63%|██████▎   | 19/30 [00:53<00:32,  2.94s/it]\u001b[A\n",
            " 67%|██████▋   | 20/30 [00:56<00:28,  2.82s/it]\u001b[A\n",
            " 70%|███████   | 21/30 [00:58<00:24,  2.71s/it]\u001b[A\n",
            " 73%|███████▎  | 22/30 [01:01<00:22,  2.76s/it]\u001b[A\n",
            " 77%|███████▋  | 23/30 [01:03<00:18,  2.69s/it]\u001b[A\n",
            " 80%|████████  | 24/30 [01:06<00:15,  2.67s/it]\u001b[A\n",
            " 83%|████████▎ | 25/30 [01:09<00:14,  2.81s/it]\u001b[A\n",
            " 87%|████████▋ | 26/30 [01:12<00:11,  2.86s/it]\u001b[A\n",
            " 90%|█████████ | 27/30 [01:15<00:08,  2.89s/it]\u001b[A\n",
            " 93%|█████████▎| 28/30 [01:18<00:05,  2.76s/it]\u001b[A\n",
            " 97%|█████████▋| 29/30 [01:20<00:02,  2.72s/it]\u001b[A\n",
            "100%|██████████| 30/30 [01:23<00:00,  2.77s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Agent : Dyna-Q, epsilon : 0.400000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
            "  3%|▎         | 1/30 [00:02<01:23,  2.88s/it]\u001b[A\n",
            "  7%|▋         | 2/30 [00:05<01:20,  2.89s/it]\u001b[A\n",
            " 10%|█         | 3/30 [00:08<01:17,  2.87s/it]\u001b[A\n",
            " 13%|█▎        | 4/30 [00:10<01:07,  2.61s/it]\u001b[A\n",
            " 17%|█▋        | 5/30 [00:12<01:02,  2.50s/it]\u001b[A\n",
            " 20%|██        | 6/30 [00:15<01:00,  2.51s/it]\u001b[A\n",
            " 23%|██▎       | 7/30 [00:18<00:58,  2.56s/it]\u001b[A\n",
            " 27%|██▋       | 8/30 [00:21<00:59,  2.69s/it]\u001b[A\n",
            " 30%|███       | 9/30 [00:23<00:57,  2.74s/it]\u001b[A\n",
            " 33%|███▎      | 10/30 [00:27<00:57,  2.85s/it]\u001b[A\n",
            " 37%|███▋      | 11/30 [00:29<00:51,  2.70s/it]\u001b[A\n",
            " 40%|████      | 12/30 [00:32<00:49,  2.75s/it]\u001b[A\n",
            " 43%|████▎     | 13/30 [00:34<00:46,  2.75s/it]\u001b[A\n",
            " 47%|████▋     | 14/30 [00:38<00:45,  2.84s/it]\u001b[A\n",
            " 50%|█████     | 15/30 [00:40<00:40,  2.70s/it]\u001b[A\n",
            " 53%|█████▎    | 16/30 [00:43<00:38,  2.77s/it]\u001b[A\n",
            " 57%|█████▋    | 17/30 [00:46<00:35,  2.76s/it]\u001b[A\n",
            " 60%|██████    | 18/30 [00:48<00:32,  2.67s/it]\u001b[A\n",
            " 63%|██████▎   | 19/30 [00:50<00:28,  2.55s/it]\u001b[A\n",
            " 67%|██████▋   | 20/30 [00:53<00:27,  2.73s/it]\u001b[A\n",
            " 70%|███████   | 21/30 [00:56<00:23,  2.66s/it]\u001b[A\n",
            " 73%|███████▎  | 22/30 [00:58<00:20,  2.62s/it]\u001b[A\n",
            " 77%|███████▋  | 23/30 [01:01<00:18,  2.64s/it]\u001b[A\n",
            " 80%|████████  | 24/30 [01:04<00:15,  2.63s/it]\u001b[A\n",
            " 83%|████████▎ | 25/30 [01:07<00:13,  2.75s/it]\u001b[A\n",
            " 87%|████████▋ | 26/30 [01:10<00:11,  2.78s/it]\u001b[A\n",
            " 90%|█████████ | 27/30 [01:12<00:08,  2.73s/it]\u001b[A\n",
            " 93%|█████████▎| 28/30 [01:15<00:05,  2.67s/it]\u001b[A\n",
            " 97%|█████████▋| 29/30 [01:17<00:02,  2.63s/it]\u001b[A\n",
            "100%|██████████| 30/30 [01:20<00:00,  2.68s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Agent : Dyna-Q, epsilon : 0.800000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
            "  3%|▎         | 1/30 [00:03<01:34,  3.26s/it]\u001b[A\n",
            "  7%|▋         | 2/30 [00:05<01:26,  3.07s/it]\u001b[A\n",
            " 10%|█         | 3/30 [00:08<01:18,  2.89s/it]\u001b[A\n",
            " 13%|█▎        | 4/30 [00:11<01:13,  2.83s/it]\u001b[A\n",
            " 17%|█▋        | 5/30 [00:14<01:11,  2.87s/it]\u001b[A\n",
            " 20%|██        | 6/30 [00:16<01:08,  2.85s/it]\u001b[A\n",
            " 23%|██▎       | 7/30 [00:19<01:04,  2.80s/it]\u001b[A\n",
            " 27%|██▋       | 8/30 [00:22<01:02,  2.82s/it]\u001b[A\n",
            " 30%|███       | 9/30 [00:25<00:59,  2.81s/it]\u001b[A\n",
            " 33%|███▎      | 10/30 [00:27<00:53,  2.69s/it]\u001b[A\n",
            " 37%|███▋      | 11/30 [00:30<00:50,  2.67s/it]\u001b[A\n",
            " 40%|████      | 12/30 [00:32<00:47,  2.62s/it]\u001b[A\n",
            " 43%|████▎     | 13/30 [00:35<00:45,  2.68s/it]\u001b[A\n",
            " 47%|████▋     | 14/30 [00:38<00:42,  2.67s/it]\u001b[A\n",
            " 50%|█████     | 15/30 [00:40<00:38,  2.57s/it]\u001b[A\n",
            " 53%|█████▎    | 16/30 [00:43<00:38,  2.74s/it]\u001b[A\n",
            " 57%|█████▋    | 17/30 [00:46<00:35,  2.74s/it]\u001b[A\n",
            " 60%|██████    | 18/30 [00:49<00:32,  2.75s/it]\u001b[A\n",
            " 63%|██████▎   | 19/30 [00:52<00:30,  2.79s/it]\u001b[A\n",
            " 67%|██████▋   | 20/30 [00:54<00:27,  2.73s/it]\u001b[A\n",
            " 70%|███████   | 21/30 [00:57<00:26,  2.90s/it]\u001b[A\n",
            " 73%|███████▎  | 22/30 [01:00<00:23,  2.89s/it]\u001b[A\n",
            " 77%|███████▋  | 23/30 [01:03<00:20,  2.90s/it]\u001b[A\n",
            " 80%|████████  | 24/30 [01:06<00:16,  2.78s/it]\u001b[A\n",
            " 83%|████████▎ | 25/30 [01:08<00:13,  2.71s/it]\u001b[A\n",
            " 87%|████████▋ | 26/30 [01:11<00:10,  2.70s/it]\u001b[A\n",
            " 90%|█████████ | 27/30 [01:14<00:08,  2.70s/it]\u001b[A\n",
            " 93%|█████████▎| 28/30 [01:17<00:05,  2.94s/it]\u001b[A\n",
            " 97%|█████████▋| 29/30 [01:20<00:02,  2.83s/it]\u001b[A\n",
            "100%|██████████| 30/30 [01:23<00:00,  2.77s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc8AAAEYCAYAAAA6Q328AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXhNV/fA8e8miYQQxBQJYiYhJIKiqLaUDqp0QFWrWtqitNX57a9zqzOqtFrzTM1DtSivFjWTSRJDQkREQmSQOdm/P87VN9WEDPfm3iTr8zyeJOeeYd3b1LL32WctpbVGCCGEEIVXydoBCCGEEGWNJE8hhBCiiCR5CiGEEEUkyVMIIYQoIkmeQgghRBFJ8hRCCCGKSJKnEEIIUUSSPIUQQogikuQphKhwlFLBSqk7rB2HKLskeQpRBiilIpVSaUqpZKXUVaXUXqXUc0opq/w/rJR6SikVqJRKVUpdVErNVEq5FPNcW5VSH+Sz/UHTue1KHvE/aa29tda7zH1eUXFI8hSi7HhAa10daAJMAV4H5pR2EEqpV4DPgFcBF+A2wBP4TSllX4xTLgBGKKXUDdufAJZorbOLGJ/Zk60QN5LkKUQZo7VO1FpvAB4DnlRKtVNKvaqUWp13P6XUdKXUNNP3kUqpyUqpAKVUolJqhVLK0fTaG0qp06ZRbYhS6qGCrq2UqgG8D0zQWm/VWmdprSOBR4FmwPBivKV1gCvQM891agH3AwsLE6Pp/b2ulAoArhXy87j7Vp+N6XU/pdRR07VXmV7/qIDPx0UptUwpFW/a/5i1ZgeEZcl/VCHKKK31AeA8RtJZDPRXStWEv0dfQzElH5NHgf5AU8AHeMq0/bTpHC4YiXGxUsqtgMt2BxyBNTfEkgJsAfrld5BpWndmAe8jDVgJjLwh1lCt9fEixDgMuA+oSeE+j7zy/WyUUg7AWmA+UBtYBhT4jwuMEXkOxuyACzBCa517k/1FGSXJU4iy7QJQW2sdA+wGHjFt7w/Ea60P59l3utb6gtb6CrAR6AigtV5l2p6rtV4BnAS6FHC9Oqbz5jeVGgPUze8grfULWusXbvI+FgAP5xnxjTRtu358YWKcrrWO0lqnFfLzuPHYf302GFPSdqbXs7TWa4ADN3kfWabYUk2xBt1kX1GGSfIUomxzB66Yvl8AjDB9PwJYdMO+F/N8nwo4AyilRpqmF68qpa4C7TCSJEqpx5VSKaY/vwDxQJ0C7iu6mV4vMq31n6ZjBymlmmMkxqXXX79ZjHlE3fDzrT6PvPL9bICGQLT+Z+/GG6+TVygwGWPqeOxN9hNlnCRPIcoopVRnjOT5p2nTOsBHKdUO437hkkKcownwIzAecNVa1wSCAAWgtV6itXY2/RkA7AMygME3nMcZGADsKsFbWogx4hwB/Kq1ji1MjHnc2Jy4yJ9HPmIA9xsWMzXKb0el1EBTjH5a66pa6x+KcT1RRkjyFKKMUUrVUErdDywHFmutAwG01unAzxgjtgNa63OFOF01jKQTZzr3KIxRXb601okY9xy/VUr1V0rZK6U8Me5ZxlO8BHXdQuBu4FnyTNkWNcY8sRbn87jRPox7mOOVUnZKqQcpeEq7HRANXE/6jU0Ln0Q5JMlTiLJjo1IqGWPa8G3ga2DUDfssANpz8ynKv2mtQ4CvMJJErOnYPbc45nPgLeBLIBmIAKoCd2utr+V3jFLqe6XU97c4bySwFyNZbihJjHkU6fPIJ6ZMjFH2aOAqxqh4E8bo+0bzgEwgyjS1vAbjfqkoh9Q/p/KFEGWZUqoxxn23BlrrpFK65ijgA6BHMUd3FmOJz0MptR/4Xms9zxznE2WT/KtIiHLC9Dzhy8Dy0kqcAFrreUqpbIzHWGwmeZrr81BK9QbCMKalH8d4lGWrWYIUZZYkTyHKAaVUNYwpzbMYj2WUKq11saZFLcXMn0drjHu61YAzwMOmR2FEBSbTtkIIIUQRyYIhIYQQoohk2raCqFOnjvb09LR2GEL8Q3p6OgCOjo632FMI6zh8+HC81vpflbMkeVYQnp6eHDp0yNphCPEPYWFhALRu3drKkQiRP6XU2fy2y7StEEIIUUQy8hRCWI2bW0HNW4SwbZI8hRBWU6NGDWuHIESxSPKswLKysjh//vzfizbEPzk6OuLh4YG9vb21Qym3UlNTAahataqVIxGiaCR5VmDnz5+nevXqeHp68s+mEUJrzeXLlzl//jxNmza1djjlVlSU0d1LFgyJskYWDFVg6enpuLq6SuLMh1IKV1dXGZULIfIlybOCk8RZMPlshBAFkeQphBCiXDp1KYXPt4ZiiTK0kjyFEEKUO5sCLjBwxp8sPxhFTKL5b7/IgiEhhNW4u7tbOwRRzmRk5zDll1Dm7YmknXsNZj/hT8OaTma/jow8RbmzdetWWrduTYsWLZgyZUq++zz99NPUq1ePdu3alXJ0Ii9nZ2ecnZ2tHYYoJ2IS0xg6+y/m7YlkWJdGrBrb3SKJEyR5inImJyeHcePG8csvvxASEsKyZcsICQn5135PPfUUW7dKP2NrS0lJISUlxdphiHLgz5PxDJj2B+EXk/l2mC+fDvbByaGyxa4nyVNY3datW+nYsSMdO3aka9eu5ObmFvtcBw4coEWLFjRr1gwHBweGDh3K+vXr/7Vfr169qF27dknCFmYQHR1NdHS0tcMQZVhurubbHScZOXc/dZ2rsHHC7TzQoaHFryv3PAUA728MJuRCklnP6dWwBu8+4H3L/SZMmMDu3bsLrHPas2dPkpOT/7X9yy+/5O677/7HtujoaBo1avT3zx4eHuzfv7+IkQshyoKrqZlMXH6M/4bH8UCHhkwZ3J5qVUonrUnyFFZ377334uPjw+OPP87UqVP/9foff/xhhaiEELbsyLkExi85wqXkDD580JsRtzUp1WezJXkKgEKNEC1h7969aK2JiYnBzi7/X8eijDzd3d3/LvkGRglCWdEpRPmy6lAUb64JpIGLI2te6I6PR81Sj0GSp7CqVatW0apVK+zs7NBak5yc/K9OG0UZeXbu3JmTJ08SERGBu7s7y5cvZ+nSpeYOWwhhBelZObz2cwAbjl/gtma1mfV4J2pVc7BKLLJgSFjVsGHD+OGHH/Dx8eG2227j5MmTJTqfnZ0dM2bM4J577qFt27Y8+uijeHsbo+p7772XCxcu/H3dbt26ERYWhoeHB3PmzCnxexFF16hRo3/coxaiIKfjUrj/2z/ZcPwCE+5swZJnbrNa4gRQlihbJGyPv7+/PnTo0D+2nThxgrZt21oporJBPiMhrG9zQAxvrAkADdOH+dKnTb1Su7ZS6rDW2v/G7TJtK4SwmqQkY4W3NMUW+cnOyeWrbeHM2nWaDo1qMmOYL41q20bvV0meQgiriYmJASR5in+LSUzj5RXH2XfmMkM7N+LDQe2wr2w7dxoleQohhLAp+05fZuLyoySnZ/PlIx14uJOHtUP6F0meQgghbILWmp/+iOCzraG41XRk0egetG5Q3dph5UuSpxBCCKtLSs/i9Z8D+CXoIv286vPZEB+rrqa9FUmeQgghrOpMXArjlh4lPDaZV+9pzfO9m1OpUulVCyoOSZ5CCKtp0qSJtUMQVrbi4DneWReMk0Nl5jzpzx2tS+8xlJKQ5CmEsBpHR0drhyCsJCsnlw83hbBw31l6tqzDFw93oIFL2fl9sJ11v0KYya2aYUdFRdGnTx+8vLzw9vZm2rRpVohSAFy9epWrV69aOwxRys4npPLI9/tYuO8sz/ZsyvxRXcpU4gQZeYpy5noz7G3btuHh4UHnzp0ZOHAgXl5ef+9jZ2fHV199hZ+fH8nJyXTq1Im+ffv+Yx9ROmJjYwGoWbP0C3sL69gZeomJy4+SnauZMdyX+30s33vTEmTkaWVKqUZKqZ1KqRClVLBSaqJp+3tKqWil1DHTn3vzHPOmUuqUUipMKXWP9aI3j9Juhu3m5oafnx8A1atXp23bttKQWQgLy87J5YtfQxk1/yBuLk5sGH+75RPn1SjYN9Mip5aRp/VlA69orY8opaoDh5VS20yvfaO1/jLvzkopL2Ao4A00BLYrpVpprXNKFMUvb8DFwBKd4l8atIcB/542vZE1m2FHRkZy9OhRunbtess4hRDFE5ecwQtLDnMwMoHH/Bvx/oPeONpXttwFtYbAVbBxEqDBayC4mLfQgiRPK9NaxwAxpu+TlVIngJs1oHwQWK61zgAilFKngC7APosHayHWaoadkpLCkCFDmDp1qpSHE8JCjkdd5YUlR7h8LYOpj3VkkK+F++tei4eNEyF0E3h0gSE/mT1xgiRPm6KU8gR8gf1AD2C8UmokcAhjdJqAkVj/ynPYeQpItkqpMcAYgMaNG9/84oUYIVqCtZphZ2VlMWTIEB5//HEGDx5cwnchhMjPqkNRvLM+CNdqVfj5ue60c3ex7AXDthqJMzUe+n0EXZ+HypZJc5I8bYRSyhlYDUzSWicppWYBHwLa9PUr4OminFNrPRuYDUZLMvNGbB7WaIattWb06NG0bduWl19+2SzvQxRP06ZNrR2CsID0rBze3xjMsgNRdGvmytShHalfw4KraTOvwfb34MBsqN8Ohi+Hhr6Wux6yYMgmKKXsMRLnEq31GgCtdazWOkdrnQv8iDE1CxAN5O0e7GHaViZZoxn2nj17WLRoEb///vvfC5W2bNlijrcjisjBwQEHB9stwSaK7kxcCkNm7WXZgSiev6M5i5/patnEeW4/fH+7kTi7Pgejt1k8cYI0w7Y6pZQCFgBXtNaT8mx3M90PRSn1EtBVaz1UKeUNLMVIpg2BHUDLWy0YkmbYxSOfkWVduXIFgNq1a1s5EmEO649F88bqQJwcKvPZEB/6etW33MWyM2DXp7D3W6jeEAZ9B017mf0y0gzbdvUAngAClVLHTNveAoYppTpiTNtGAmMBtNbBSqmVQAjGSt1xJV5pK4SVxMXFAZI8y7r0rBw+2BTC0v3n8G9Si28e62jZptXn9sO65+HKafAZCv0/haql+zskydPKtNZ/AvlVQC5wHlFr/THwscWCEkKIQrqUlM4zCw8RcD6RMb2a8eo9rS3XtDonG/78BnZ9AtXdYMRqaHH3rY+zAEmeQgghimXvqXgmLDvKtcxsZj/RiX7eDSx3sbhwWP8CnD8I3oPhgangaOHVuzchyVMIIUSR5ORqpm4P59vfT9GsbjVWjL2NFvUs1LQ6N9dYDLT9XahcBYbMgXZDQFm3ZZkkTyGEEIUWn5LBSyuO8cfJeB7p5MH7D3pT1cFCqeTyaVg/Ds7tgxZ9YdBMcLaNlmWSPIUQVtO8eXNrhyCK4GDkFV5YcoSktCw+eag9w7o0QlliBJiTZayi3fUp2DnBwG/B9wmrjzbzkuQphLCagqpKCduitWbenkim/BKKey0n5o/qjHdDC91vvBRqrKS9cATaPgADPocattd5RX5zhRBWc/nyZQBcXV2tHIkoyLWMbF77OYDNgTHc3bYeXz7SgZpVLVDYIicL/pwKuz83RpsPzzXubdooqTAkyp1bNcO+LicnB19fX+6///5SjE7kFR8fT3x8vLXDEAU4EZPEwBl/sjX4Iq/3b8OPI/0tkzgvnYC598DOj6DVPTD+oE0nTpCRpyhnCtMM+7pp06bRtm1bkpKSrBCpELZt1aEo/rMuCBcnexY+3YUeLeqY/yLZmfDXd7DzU6hS3VhJ2/5h81/HAmTkKayutJthg9FtZfPmzTzzzDMlCV2IcictM4dXVx3n1Z8D8Gtci80v9rRM4rx8GubfZxR0b3E3PL+nzCROkJGnMPnswGeEXgk16znb1G7D611ev+V+1miGPWnSJD7//PN8zytERXU6LoVxS44QejGZsb2b8XLfVlSxM3PTaq2NlbQ7P4HK9jBwBviOsKmVtIUhyVNYXWk3w960aRP16tWjU6dO7Nq1y6znFqKs+jX4Iq/9HIBSWK5aUFwYbHoZzv4Jre+F+76yyZW0hSHJUwAUaoRoCdZohr1nzx42bNjAli1bSE9PJykpiREjRrB48WIzvCNRFC1btrR2CBVeVk4uU7eH893O03g3rMGsxzvR2NXMRd21hmNLYPNkUJXg/m/A7ymoVHbvHEryFFZljWbYn376KZ9++ikAu3bt4ssvv5TEaSWVyvBfnuVB1JVUJi4/ypFzV3nMvxHvDfTGycHM07SJ0fDLaxC6CTx7wqBZULPRrY+zcfKbK6zKGs2whe2Ii4v7uy2ZKF37z1zmoZl7OHkphenDfPnsYR/zJ86g1TCzG5zaDne/DyPXl4vECdIMu8KQZtjFI5+RZYWFhQHQunVrK0dSceTkaqZtD+e7XadpUrsqs0d2Mn9R92vxsPUNCFwFHp1h8I9Qu6l5r1FKpBm2EEJUcImpWUxYfpTd4XEM9nPn/YHeVHe0N+9FQjfDhgmQngS934Bek41VteWMJE8hhKgAAs5f5YUlR4hNSufTwe0Z1qWxeS+QEmfc2wxeA/W84Im14NbBvNewIZI8hRCiHNNas2T/OT7YGELd6lVYObYbvo1rmfcioZth00uQlgB3vAW3vwR2FijjZ0MkeQohRDmVmJbFaz8f59fgWHq3qss3j3WkdjUzJrXMVPj1TTg8H+q0Mkab9b3Nd34bJslTCGE1slDIco6eS2D80qPEJqXzxoA2jOnZjEqVzFjF58IxWPUkJERCj4lw5zvl8t5mQSR5CiFEOaK1Zu6eSD7bGkr9GlVYMbYbnZqYcZo2J9toG7b7S6haG0asNmrTVjCSPIUQVhMbGwtA/fr1rRxJ+ZCSkc1bawLZcPwCd7etz5Qh7anjXMV8F4g5DhsnwoWj4PMYDPgMnMx8/7SMkOQphLCaq1evApI8zSEoOpEJy45y7koqk/u1YlyfFihzFVvPzYWDP8Kvb4NjjTLVOsxSpMKQKHcK0wz7m2++wdvbm3bt2jFs2DDS09NLOUohzENrzeK/zjLouz1cy8hm0egujL+zpfkSZ0IkLLjfeAylWW8Yf6jCJ06Q5CnKmevNsH/55RdCQkJYtmwZISEh/9gnOjqa6dOnc+jQIYKCgsjJyWH58uVWiliI4ktMzWLsosP8Z10Q3Zq7su2l3nRvbsbemwGrYGZ3uBhotA57/GfjPqeQ5GkLlFKNlFI7lVIhSqlgpdRE0/baSqltSqmTpq+1TNuVUmq6UuqUUipAKeVn3XdQMtZohp2dnU1aWhrZ2dmkpqbSsGHZbIskKq7gC4kMmrmHnWGXePvetiwY1QWXqmZa7Zp6BdY+D2uegQbt4bk/we+JMtdz05LknqdtyAZe0VofUUpVBw4rpbYBTwE7tNZTlFJvAG8ArwMDgJamP12BWaavxXbxk0/IOGHeZthV2rahwVtv3XK/0m6G7e7uzuTJk2ncuDFOTk7069ePfv36FeYtCTOTripFp7Vm1eHzvLs+GBcnexaP7krXZq7mu0DoZtj8ilGf9vaXoc9bFeoRlMKS5GkDtNYxQIzp+2Sl1AnAHXgQuMO02wJgF0byfBBYqI2q/n8ppWoqpdxM5ylzSrsZdkJCAuvXryciIoKaNWvyyCOPsHjxYkaMGGHW64hbk36eRZOelcM764JYdfg8/k1qMWO4Hw1cHM1z8rQE2PomHF8GddvAsOXQsKN5zl0OSfK0MUopT8AX2A/Uz5MQLwLXlyS6A1F5Djtv2lbs5FmYEaIlWKMZ9vbt22natCl169YFYPDgwezdu1eSp7BpUVdSeX7JYYKik3jm9qa8MaANdpXNNHIPXgebJhnF3Hu9Cr1eK/fl9UpKkqcNUUo5A6uBSVrrpLyr5bTWWilVpP5xSqkxwBiAxo3NXATaTKzRDLtx48b89ddfpKam4uTkxI4dO/D3/1fHIVEKYmKMf+8VNGUvDP8Nj2PS8qPkapj9RCf6eTcwz4lTr8DmlyF4rXFv84kZMtosJLnhYCOUUvYYiXOJ1nqNaXOsUsrN9LobcMm0PRrI21HWw7TtH7TWs7XW/lpr/+ujLFtjjWbYXbt25eGHH8bPz4/27duTm5vLmDFjzPF2RBElJSWRlJRk7TBsVmZ2Lu9tCObJuQdwda7CunE9zJc4w3+DWd3hxCajtN6zOyVxFoE0w7YByhhiLgCuaK0n5dn+BXA5z4Kh2lrr15RS9wHjgXsxFgpN11p3udk1pBl28chnZFnSDLtgcckZPL/4MIfOJjCqhyev92+Do33lkp848xrs+AD2fw+uLeGhH8CjU8nPW05JM2zb1gN4AghUSh0zbXsLmAKsVEqNBs4Cj5pe24KROE8BqcCo0g1XCGFJO0Mv8cqq46RkZPPtMF8e6GCmR6nO7oM1z0JiFHR6CvpPAXsn85y7gpHkaQO01n8CBT1AdVc++2tgnEWDEkKUuuycXKZuP8l3u07Run51Voy5jZb1q5f8xJmpsPNj2DcDajaBUVuhSbeSn7cCk+RZwWmtzVfGq5yRWxqWV9AK64royrVMnllwkCPnrjLY150PBrXDuYoZPp/YYFg1CuLDwG8k9P0QnGqW/LwVnPzmVmCOjo5cvnwZV1dXSaA30Fpz+fJlHB3N9AydyFfz5s2tHYJN+OvMZV5acYz4lAy+eNiHR/wb3fqgW9Ea9v8A294Bh2rw2BJoe3/Jz1uGaK05k3iG5jXN/3smybMC8/Dw4Pz588TFxVk7FJvk6OiIh4eHtcMQ5ZjWmiX7z/HBphAaujiy+vnu+HiYYVSYcgk2vQShm6BFX3jwO6hesTrXHIg5wPSj0wlPCGfTQ5uoV7WeWc8vybMCs7e3p2nTptYOQ1Rg0dHGE1Y3FrKoCFIzs5m86jhbAi/So4UrM4b5UauaGQoThGyADeONVbX9PoJu4ytUTdojsUeYeWwm+y/up45THd7s8iZ1nMxYLN9EkqcQwmpSUlKsHYJVBF9IZMzCw8QkpvHmgDY827MZlSqVMMGlJ8LWt+DYYqjbFh6ZB/UqzmNW4QnhzDg6g51RO3F1dOVV/1d5pPUjONlZZjWxJE8hhCglWmsW7z/HR5tCqOFkz7JnbzNPUfdTO2D9eEi5CD1fgTverDDF3C9eu8i0I9PYfGYzVe2rMr7jeEZ6j7RY0rxOkqcQQpSCtMwc3l4XyJoj0XRv7sr0Yb7Uca5SspNmpMD2d+HgT1CrKYzeXmEKHly8dpGFIQtZEboCpRSj2o3i6XZP41LFpVSuL8lTCCEsLDw2mReXHSUsNpmJd7Vk4l0tSz5NG/EHbJwICRHQ9Tm4611wqGqegG1YXGocc4PmsjJsJZm5mQxsPpDnOjxHo+pmWKFcBJI8hRBW4+BQ/jt3rDlynv+sC6KqQ2XmPtmZPm1KuOozKw22vw/7Z0HtZvDEOmjW2zzB2rC41DjmBM3h5/Cfyc7NZmDzgYzxGYNHdeusiJfkKYSwmvK82jsrJ5f/Wx/MsgPn6OxZi++G+1GvRgmfG446AOvHQXw4dBkLd79rPMNZjl1Nv8rc4LksD11OZk4mDzR/gDE+Y0p9pHkjSZ5CCGFmUVdSmbj8KEfOXWX07U15vX8bHOxK0MQqJwv2TIVdU6B6Q3hiLTS/03wB26CUzBTmBM1hWegyUrNS6e/Zn/G+42lcwzbaK0ryFEJYzfXG5Y0aWXcUYU6/BV/klZXHQWGeou6xIbB2LFwMAO+H4P6p5bq8XkpmCj8F/sTS0KWkZadxV+O7GNdxHC1rtbR2aP8gyVMIYTWpqanWDsFsMrNz+WxrKHP+jMDHw4Vvh/nSxLUEU6o52cYq2h3vG1Ozjy4Cr4HmC9jGpGalsix0GfOC55GYkUh/z/485f0U3nW8rR1aviR5CiFECZ27nMrzSw4TfCGJYV0a8+4DXiXrvXn5tHFv89w+Y3p20CyobqYm2DYmV+ey5uQavjv2HfFp8XR168pLnV7C29U2k+Z1hUqeSqkGwFSgM3AViAUmaa3DLRGUUmoXMFlrfegm+0wCZmutU00/bwGGa62vWiImIYTIz/Vp2uxczedDfHi0cwmmoLWGv2Yazaor2Rs1aTsMh0oluF9qo7TW7IzaybdHv+XU1VP41fPjy95f4lfPr0w0qrhl8lTGu1gLLNBaDzVt6wDUByySPAtpErAYoxk0Wut7rRiLEKKCScvM4ettYfz4hzFN+91wPxrVLsFzlpdPG89tRv4BrQbA/d9ADTfzBWxDAuMCmXFsBnsv7MWzhief9/qc/p79y0TSvK4w/5zpA2Rprb+/vkFrfRyorJTadH2bUmqGUuop0/eRSqlPlVLHlFKHlFJ+SqlflVKnlVLPmfa5o6Dj81JKzTKdI1gp9b5p24tAQ2CnUmpnnmvWUUpNUUqNy3P8e0qpyabvX1VKHVRKBVw/lxDCehwdHctk27czcSk8+sM+fvwjguFdG7NybLfiJ06t4eAc+KE3xByHe7+EYcvKZeIMTwjnue3PMXzLcEIuh/Cq/6usfXAtA5oOKFOJEwo3bdsOOFyMc5/TWndUSn0DzAd6AI5AEPD9zQ68wdta6ytKqcrADqWUj9Z6ulLqZaCP1jr+hv1XYEwxf2f6+VHgHqVUP6Al0AVQwAalVC+t9e5ivDchhBk0adLE2iEU2Y4TsUxafgyl4KeR/tztVYJWX+lJxr3NExvAsycMmgk1beNRDHM6m3SWmcdmsjVyK9UdqjPJbxJD2wylmn3ZfUbVkguGNpi+BgLOWutkIFkplaGUKso660eVUmMwYnUDvICAgnbWWh9VStVTSjUE6gIJWusopdREoB9w1LSrM0YyleQphLil3FzNzF2n+HpbOF4Na/D9iE541CrBNG3EH0biTIyCO9+BHhPLXTH388nn+SHgB7ac2ULlSpUZ6TWS0e1GU9Ox7D9qU5jkGQw8nM/2bP457Xvj3EuG6Wtunu+v/2xXiONRSjUFJgOdtdYJSqn5+e2Xj1WmmBtgjETBGG1+qrX+oRDHCyFKwdmzZwHbH4FeTsng9dUBbD9xift93Pj8YR+qOhRz7PGPYu6eMGorNO5q1nitLfZaLLMDZrPm1Boqq8o82OJBxvqMpX618tOQuzD/9X8HPlFKjdFazwZQSvlgJCMvpVQVwAm4C/izCNc+W4jjawDXgESlVH1gALDL9FoyUB24cdoWjIT5I1AHuF708VfgQ7pWuAYAACAASURBVKXUEq11ilLKHeNe7qUixCyEMKP09HRrh3BLR88lMH7pUeKSM3jnfi+e7uFZ/PtzEX/A+hfg6jmjvF7f98Hesq2zStP1ou2rwleRo3MY3GIwY3zGlKuked0tk6fWWiulHgKmKqVeB9KBSIzVrisx7mFG8L/p0EIxTaXe9Hit9XGl1FEgFIgC9uR5eTawVSl1QWvd54bjgpVS1YForXWMadtvSqm2wD7TL34KMAKQ5CmE+BetNXP+jOCzraHUq+7Ique60aFRMacbs9Jh2//BgR+MYu6jfoEm3c0bsBXFXotlfvB8Vp9cTUZOBvd43sOLvi9arWh7aVBaa2vHIEqBv7+/PnSowMdmhbCKsLAwAFq3bm3lSP4pLjmDN1YHsCP0Ev286jNliA+1qxWzA8y5/bBhAsSHlbti7hevXWR2wGzWnVpHrs7lvmb38Wz7Z/F08bR2aGajlDqstfa/cbtUGBJCiDyOnkvg+cVHSEjN5N0HvHiqezGnabPS4PePYN93ULMRPL4aWt5t/oCtICkziQXBC5gfNB+N5qEWDzGq3ahyPdK8kSRPIYTVVK1qO82btdbM3xvJh5tCcHNxYs0L3fFu6FK8k8UEwNLHIPkCdBoFd79XLoq5p2alsuTEEuYHzycpM4n+nv2Z1GkS7s7u1g6t1EnyFEJYja10U7mamslrPwfwW0gsfVrXZepQX1ycivHYSE4W/PE1/HcKONWGYcuh9QDzB1zKUjJTWBG2goUhC7mSfoXeHr0Z7zueNrXbWDs0qyk3yVMpdQdGPdz7rR1LUSml5gL3A5e01u1M294DngXiTLu9pbXeYnrtTWA0kAO8qLX+tdSDFqKcCIpOZMzCQ8SnZPLWvW14tmez4k3Txp80WodFH4Z2Q4xKQVVrmz/gUpSYkcjSE0tZfGIxSZlJdG/YnXEdx+FT18faoVmdxZKnqSau0lrnWuj8lbXWOZY4txXMB2YAC2/Y/o3W+su8G5RSXsBQwBujROF2pVSrcvRZiAokIiICgKZNm5b6tbXWLD8YxbsbgqlV1Z5Fo7vQtZlr8U4Wsh42vAhKweAfof0jxvdl1PV7motCFpGWnUafRn0Y4zOGdnXaWTs0m2HW5KmU8sR4nnI/0AlYqZS6H6gCrNVav6uUehXIMJXY+wbooLW+Uyl1JzBaa/24UmoWRgcXJ+BnrfW7pvNHYjzD2Rf4XCl1FaMUXypFe8bUpmitd5s+u8J4EFiutc4AIpRSpzBKDu6zUHhCWExmZqZVrpuYmsVrq4/za3AsPVq48u0wv+Ktpk2+CL+8DiHrwK0jPDIfapf+PwTMJTkz2ZieDV5IQkYCfRr1YbzveFrVamXt0GyOJUaeLYEnMQocPMwNtWSBP4BXgOmAP1BFKWUP9OR/pfLyq2d7vSTfZa21n1LKETgJ3Amc4n+VhMqT8UqpkcAh4BWtdQLgDvyVZ5/zpm3/YiprOAagcePyVy9TiOI4FHmFCcuOEp+Swdv3tmX07U2pVKmIo0StIWg1bHoZstPgrv+D7i+W2fJ6iRmJLAxZyLITy0jOSqaHew9e6PCCTM/ehCWS51mt9V9KqS/Jv5bsQqCTUqoGRtm+IxhJtCfwomnfm9WzvZ4k2wARWuuTAEqpxZgSRTkxC/gQ0KavXwFPF+UEpopQs8F4ztPcAQpRluTmar79/RTTdoTTqHZVVj/fHR+PYqyATYqBLZMhdBO4+8NDP0CdFuYPuBRcy7rGstBlLAxeyNWMq8b0bIcxNt+I2hZYInleM30tsJasUioCeArYi5EU+wAtgBOFqGd7jQpAax17/Xul1I/A9fZt0UDeJYoepm1CiAJcTslg8qrj7AyL4x7v+nzxSAdqOBZxlJibA4fnw/b3IScD+rwNPV+BSpUtErMlJWUmsTx0OQtDFpKYkcjt7rcz3ne8JM0isORq25vVkv0DI0E+jdF15WvgsKkU4M3q2eYVCngqpZprrU8Dwyz4XkqdUsrtemlB4CGMMoZgdKtZqpT6GmPBUEvggBVCFKLEnJ2dLX6N/WcuM2nFMS6nZPL+QG9GdmtS9NW0KXHGStrTO6BRVxg4A+qWvfuASZlJrAhd8fdzmr09evNch+dkIVAxWCx53qKW7B/A28A+rfU1pVS6adut6tnmPX+6aWp3s1Iq1XR8dUu9H0tSSi0D7gDqKKXOA+8CdyilOmJM20YCY+Hvur0rgRCMzjTjZKWtKKvc3S33cH1uruaH3Wf48rcwGtRwZM0L3WnnXoyiB+G/GYkzIxn6/Ad6TS5zK2kTMxJZcmIJi08sJjkzmV4evRjXcRxerl7WDq3Mktq2FYTUthUVyYWraby+OoA/TsZzn48bnw3xwblKEccKKXHw61sQuBLqecPg2dCgbI3Q0rLTmBc0j4UhC7mWdY0+jfow1mcs3nVkerawpLatEMLmnD59GoDmzZub7Zy/BV/k9dUBpGfl8slD7RnWpVHRp2kjdsPKJ43RZq9XoedksC9MK2HbkJadxpqTa5gTOIe4tDj6NunLWJ+xtK5tWwX4yzJJnkIIq8nOzjbbuVIzs/lwUwjLDkTh5VaD6cN8aVGviPdU0xNhxwdwcA64NofHfwaPTmaL0dJycnNYd2ods47PIjY1Fm9Xb77o/QWd6ped91BWSPIUQpR5py4lM37pUcJik3nm9qZMvqc1jvZFXAUbuQfWPQ9Xz5a51mG5OpftZ7fzY+CPhF4JxaeuDx/f/jFd3bpaO7RyS5KnEKJMW/TXWT7aFIJzFTvmPdWZO1rXK9oJMlPht//AoTlQyxOe3ARNe1okVnPTWrPu1DrmBc8jIjGCJjWa8GnPT7mv6X3Fq88rCk2SpxCiTLqUnM4764L4NTiWXq3q8uXDPtSrUcT7kqe2w+bJkBAB3cZDn7fKzGjzz+g/+fbot4RcDqFVrVZ80esL+jbpS+Uy+NxpWSTJUwhhNTVq1CjWcUfPJTBm0WES07J49Z7WPNe7OZWLUmIv5RL8+raxkraWJ4zcAM16FyuW0pSrc9kfs5/vj3/PkUtHcHd256MeH/FA8weopCpZO7wKRZKnEMJq3NzcirR/dk4u038/xXc7T9GwpiOLRvegTYMiJGCtjSLum142VtL2fAV6vw52VYoYeenSWrMzaifTj0zndOJpGlRrwES/iTzp9ST2ZbSeblknyVMIUSZcTslg3NIj/HXmCvf7uPHBg+2K1gklb03aBj4w5Ceoa/uPbuyP2c9Xh77ixJUTNK7emHdue4cHmj+Ak52TtUOr0CR5CiGs5uTJkwC0bNnypvvtORXPaz8HcCk5nXcf8GJUjyK0/dIaAn+GX16DrDS4+z3oNgEq2/Zff0HxQXx//Hv+e/6/uDu78/HtH3Nv03uxq2TbcVcU8l9BCGE1ubm5N339+jTt9B0naVa3Gque607HRkXohHLtMmx88X8dUAbNsvmatCcun2DW8VnsjNpJDYcaTPCdwIi2I6hqX9XaoYk8JHkKIWxS9NU0Ji47yqGzCQz2defjh9rj5FDIlaRaQ8BK+O1tSLsKfT+EbuNsugNK6JVQvj/+PTvO7aCafTUm+E5gWJthVHcokyW7yz1JnkIIm7Px+AXeWhNIjtZMfawjg3yLUEA+ORa2vgHBa6ChH4xcD/Vtt5br6aunmXF0BtvPbcfZ3pkXOr7AiLYjJGnaOEmeQgibkZ6Vw/+tD2LlofN4udVg1gg/mrgW4bnLwJ9h88uQkQJ3/gd6vGSz9zbjUuOYdXwWa0+upYpdFV7o8AKPez1ODYfiPb4jSpdt/lYJISqEmjX/d/8y+EIiE5cf49SlFEZ2a8IbA9pQ1aGQf0UlnodfXjfubXp0gUEzoc7NFyFZS2JGIotPLGZ+0HxydA4PtniQiX4TqeVYy9qhiSKQ5CmEsJr69eujtWbJ/rN8uCmEGo72zHnSn7va1i/cCbSGo4vgt3cgOwPu+j/oPtEmR5vxafEsClnE8tDlpGanclfju3il0ys0qtHI2qGJYrC93zAhRIWRcC2TyauOsyP0Ere3qMPXj3WgXvVClti7csYodnBmJzTpAQO/NTqh2Jj4tHjmB81nyYkl5JLLPU3u4RmfZ2hVy7ZX/Yqbk+QphLCKP0/G88myHaRl5vDuA914spsnlQpTYi83B44uhm3vQE423Psl+I+GSrZVni4hPYF5wfNYHrqc9Ox0BjYfyDPtn8HTxdPaoQkzkOQphChVGdk5fLz5BAv3naVzrcpMursV/boXsujBpRNGsYOI3dCoq/Hcpo2NNlMyU5gbNJfFJxaTnp3OgKYDeK7DczR1KUJhB2HzJHkKIUrNiZgkJi4/SnhsCk/3aMrg5gr7yoUYMWalwe8fwV+zoIqzMdrs/AzYUNut6wuBVoat5Er6Ffp79uf5Ds/TrGYza4cmLECSpxDC4oxFQef4YGMILlXtmfuUP3e2qU9YWNitDz61w3huMz4cOj4OfT+AanUsH3QhpWenszBkIfOD5pOSlUJ39+6M7ziednXaWTs0YUGSPIUQFpWUnsVbawLZFBBD71Z1+frRDrg6F6KLSUYybH3TWE3r0hhGrIEWd1k+4EK6lnWNdafWMTdwLpfSLnGHxx2M9x1P69q2X2xelJwkTyGExRw5l8DE5Ue5cDWdV+9pzfO9m/9jUVDt2rXzPzDsF9j0EiRfhB6TjLZhDrZR2zU1K5VlocuYHzyfqxlX8avnx5ReU+jcoLO1QxOlSJKnEMLscnM1c/dEMOWXUOrXcGTl2G50avLvIgB169b954akGNj+LgSsgHpe8OgiaGQbSSkjJ4NVYav4MfBHrqRfoYd7D8b6jKVj3Y4oG7r3KkqHJE8hhFldTEzn1Z+P88fJePp51eeLRzrg4pR/w+brXVUqVaoEAatg40TIyYSek01NqovQr9NCMnIyWHdyHXOC5hBzLYauDboy3nc8Het1tHZowookeQohzGZrUAyTVwWQnZvLh4PaMaJr45uOyk6ePAkpF2kdNgvCfzHahg35EWpbf4VqalYqq8JXsSB4AXFpcfjU9eHDHh/S1a2rtUMTNkCSpxCixNIyc3hrbSBrj0bTun51vh3uS6v6t+gKkp1pdD4JWgt2F+Cud6H7i1YvrZeVm8XSE0uZEziHhIwEujTowqc9P6VLgy4yPSv+JsnTBiil5gL3A5e01u1M22oDKwBPIBJ4VGudoIz/e6cB9wKpwFNa6yPWiFsIgKDoRMYvPULk5VSev6M5L/dtdetnNy8chbXPQ1wGNLoNHlkHNRqWTsAFyM7NZmvkVmYdm8W55HP0aNiD5zo8J9OzIl+SPG3DfGAGsDDPtjeAHVrrKUqpN0w/vw4MAFqa/nQFZpm+ClGqcnM1i/46y5RfQqlWpTLfDffjPh+3mx+UeQ3++Ar2TAPHmtDrI3D3s2rizMrJYsPpDcwJmkNUchQta7Xk2zu/pbdHbxlpigJJ8rQBWuvdSinPGzY/CNxh+n4BsAsjeT4ILNRaa+AvpVRNpZSb1jqmdKIVAi6nZDB51XF2hsXRpWltpg/1pYHLLQq6n9oBWyYbBd19HoMBn8G5S6UTcD7SstNYc3IN84LmEZsai7erN1P7TKVPoz5UUrZVJ1fYHkmetqt+noR4Ebjeo8kdiMqz33nTtn8lT6XUGGAMQOPGjS0XqahQdofH8fLK4ySlZ/HeA16MvFVB9/Qk4/GTQ3ONYgdPboKmPQGoUye3lKL+n6jkKDad2cTy0OVcSb9Cp/qd+KD7B3Rr2E1GmqLQJHmWAVprrZTSxThuNjAbwN/fv8jHC5FXdk4uU7efZMbOUzSrU415T3WmvYdLwQdoDYE/w29vQ8ol6Dbe6Ldp97/qQq6urqUQuSE6JZrZAbNZf2o9OTqHHg178KzPs3Sq36nUYhDlhyRP2xV7fTpWKeUGXJ/figbyds/1MG0TwmLOJ6Ty/OIjBEYnMqhjQ94f2A6Xqvk/uwlAYjRsfsV4/KRBexi6DDz+naSys7MBsLOz3F9FEYkRrD21lkUhi6hEJYa1GcaT3k/SoFoDi11TlH+SPG3XBuBJYIrp6/o828crpZZjLBRKlPudwpI2Hr/A22sDycnVfP1oBwb7eRS8s9ZweD5s+z+j2MHd7xuPnxTQa/P06dMAtG5t/nqwkYmRLAxZyNpTa8nOzWZA0wG83OllSZrCLCR52gCl1DKMxUF1lFLngXcxkuZKpdRo4CzwqGn3LRiPqZzCeFRlVKkHLCqE1MxsPtwUwrIDUbR3d+G74X40dr1Jfdm4MNg4Cc7thcbdYNBMqxQ7uHjtItOPTGdLxBbsK9kzwHMAL/q9KElTmJUkTxugtR5WwEv/aiFhWmU7zrIRiYouKDqRl1Yc4+SlFJ7q7snb97Ut+NnNnGzY/QXsmQp2jkavTf/RBY42LeXM1TPMDpzNrxG/UrlSZR5r/RjP+jxLHSfbaV8myg9JnkKIv2mtmb83ko82n6B2NQcWPN2F3q3qFnxAzHFYPw4uBoL3YOg/BarXL3h/Cwi7EsZPgT/x29nfqFK5Co+1eYyRXiNp6GzdoguifJPkKYQA4FJyOm+sDuT30Ev0blWXaUM7UrNqAYXZs9KNkebuL6BqHXhkAXgPKtV4j106xo+BP7L7/G6q2VdjlPcoRniNkJGmKBWSPIUQ/Dc8jpdXHCM5PZt37vfi6R6eBT/zGHXAGG3Gh4PXILjva6hWvEdO/tWS7BZydS5/XfiLHwN/5FDsIWpWqckE3wkMbTOUGg41ihWDEMUhyVOICiwjO4evfgtn9u4ztGlQnQVPd6GdewHPbqYnwY734eBP4NIIhq+CVv1KdP0Cm2HfIFfnsvv8bmYHzCYwPpB6VevxWufXGNJyCFXtbaNJtqhYJHkKUUGdjE3mxeXHOBGTxLAujXn3AS8c7Svnv/OZXbBhAlyNgq7PQZ+3wbHkI73MzEwAHBzynx7O1blsP7udHwJ+IDwhHFdHV9657R0GtRiEQ2Xr9/oUFZckTyEqmJxczYK9kXz+ayhVHez4caQ/fb0KWOSTfBG2vmm0DqvdDEb/Bo26mC2WiIgI4N/PeWqt2XNhD18d+opTV0/hWcOTT27/hAFNB2BXSf7aEtYnv4VCVCBRV1J5eeUxDkYm0Kd1XT4b4kO9GvkUdM/NhcCVsOU1yE6D3q9Dj0ngYPkp0oMXDzLz2EwOxR6iUfVGfN7rc/o16UflSgWMioWwAkmeQlQQWwJjeGN1ALkavn60Aw/5uue/KCjmOPz2H4jYDR5d4KHvwbW5RWPLzs1m85nNzA2ay5nEM9RxqsNbXd9iSMshMj0rbJIkTyHKudTMbD7YGMLyg1F08HDh22EFVArKSoPt78PBH8HRxVTs4Gmw4IgvIyeDo7FHeSn4JaKSo2hdqzVvd32bQS0G4Wh3ixZnQliRJE8hyrGg6EQmLj9KRPw1xvZqxiv9WuNgl0/ln4jdsOFFSIgA3yeg34fgVMticcWkxLDxzEY2799MWnYaNT1qMq3PNPo06iNtwUSZIMlTiHJIa83i/ef4cFMINZ3sWTy6K91b5FM8ID3RGG0emmM8fvL4z9Cyr8XiikyMZF7wPDac3kB2bja93HoxpOUQ+rSSpCnKFkmeQpQzV65l8uaaAH4NjqV7c1dmDPejdrUb7htqbayg3fomXIuD216APm9BleoWiSnkcgg/Bf7E9rPbcajswJCWQ3i87eM0dWlqkesJYWmSPIUoR3aGXeLVVcdJTMvizQFteLZnMypVumFEl3IJNk6EsC1Qvx0MXwENfc0ei9aaQ7GH+CnwJ/Ze2IuzvTNPt3v6HyX00tPTAXB0lPubomyR5ClEOZCRncOnW0KZvzeSNg2qs/Dprng1vKGIQW6usRho58fG4qC+Hxgjzso3aWpdTMHxwUw7Mo19Mfuo7VibiX4Teaz1Y1R3+OfI9uzZs4Bl+nkKYUmSPIUo4/JWCnqyWxNeH9CGqg43/K8dF2bUoz1/ENw6Go+f1Gtr1ji01uy9sJe5QXM5cPEALlVcmOw/mcdaPyYrZ0W5I8lTiDJKa82cPyP44tcwnKvYMedJf+5qe0OloOwM2DcDdk0xem0OnAG+I8CMi3NydS5bIrawOGQxwZeDqedUjwm+ExjeZjjODs5mu44QtkSSpxBlUMK1TF5ZdZzfQy9xd9v6fDK4HfWq3zC6uxgEa5+D2EBo1d9InM5F62JyM9m52X/XnT119RRNajThvW7vMbD5QOwtMBUshC2R5ClEGXMs6irPLDjE1dRM3n3Ai6e639A+LCMZ/vs57PsOqrrCowvB60GzXT8jJ4P1p9YzN2gu0SnRNHVpyue9Pucez3uopPJ5hlSIckiSpxBlRHZOLtN2nGTmrtM0qOHImhe64+NR8587hf9qdD9JiTWKHdz1rtlGm9eyrrEybCULQxYSnxaPTx0fXvV/lTsa3VHsurNubm5miU2IG+msLDIjI8m6eBHnnj3Nfn5JnkKUAecTUpm4/BiHzybwkK877z3gjUvVPFOjGSnwy+twbDHUbQNDl4KHv1munZCewJITS1gaupTkzGRuc7uNz3p+RucGnUtc2KBGDWlgLUouNzOTjLBw0kNPkLr/ABknT5J55gw6KwuA1kePUMnJyazXlOQphI3bFhLL66sDyMrOZdrQjjzY0f1/L2oNRxbCtv8zqgX1fMXogGJXpcTXjUuN47tj37ElYgtp2Wnc1fgunmn/DO3qtCvxua9LTU0FoGpVaWgtCkdnZZEWGEjqgQNkhIeTERlJ5ukz6IwMAOzq1sXRy4tqt/fAsXVrHBo3Rtmb/x68JE8hbFR6Vg4fbz7Bor/O0qZBdWYM96NFvTyrVy8GwpZX4dw+aHQb3P0eNOlW4utevHaReUHzWBW+CoCBzQfyhNcTNK9p/s4qUVFRgDznKfKns7NJDw4mPTSMzHNnSTtylPSQkL8Tpb27Ow5Nm1KtS1ecfH2p0rIlDk09S6XUoyRPIWxQ2MVkJi4/SujFZJ7u0ZQ3722DfWXTYpzsTPjvZ7BnGjjVhPungt/IEnc/iUyMZG7QXDae2YjWmr5N+jLedzxNajQxwzsS4tayLl0iIzSU9LAwUvftI/XYcbRpdgI7O5y8vak1bBhOHTtQrXt3Kltx2l+SpxA2RGvNwn1n+WTLCao72vHjSH/6euV5djNyD2x6CeLDoMNw6PcRVHMt0TVvrDv7cMuHeardU7g7u9/6YCGKKfN8NKn795N57hzpISGkh54gJy7+79ertGxBzUGDqOrfCaeOHbGrUwflYDu9XSV5CmEjYpPSeX11ALvC4ujdqi5fPdqBOs6me5epV+C3d4wFQS6NYfgqaNWvRNcLiAtgdsBs/nv+vzjbOzO6/Wgeb/v433VnhTCXnMRErh04QOqBg2SeO0tGyAmy4+KMF5WiSsuWOPe4nSotW+LUwQcHT0/s6tj276EkTyFswJoj53l/YwjpWTm8P9Cbkd2a/O++TfivRmm9tAToMRF6vwEOxV9gExAXwKzjs/gz+k+c7Z150fdFhrYZ+q+6s0IUldaarOho0oNDSDtymPTgEDIiIsi5fBkAVbUqDh4eVOvenSpt2uDcuxcOHh42NaIsLEmeNk4pFQkkAzlAttbaXylVG1gBeAKRwKNa6wRrxSiKL+FaJu+sD2JTQAz+TWrx2cM+NK9rWhSUHGusog1YDnVawRNroUH7Yl8rPCGcrw9/zZ7oPbhUceFF3xcZ1maYVUvoubvL1HBZpXNyTNOtoWSeiSDz3DnSAo7/PfWqqlTB0csL5z534NC4CU4+7XHy86NSGUyU+ZHkWTb00VrH5/n5DWCH1nqKUuoN08+vWyc0UVy7w+N4eeUxLl/LZNLdLZlwZ0sqV1L/637y+0eQmQK9XoNer4Jd8f7SORBzgOVhy9l2dhvVHaoz0W8iw9oMo5p9NTO/o6Jzdpbat2WBzswkPSSEawcOknn6NJnR58kICyc3ORkAZW+PfZPGVOt6G1X9O+Ho7U2V1q3LTaLMjyTPsulB4A7T9wuAXUjyLDOuZWTz0eYQlh2IolV9Z+Y91YX2Hi7Gi5dPw+pn4MIRaNIDHpgGdVoW+Rpaa/6I/oOZx2YSfDmY6vbVGeU9ipHeI23qnmZKSgogSdRWaK3JuXyZtIAAMsJPknHmNJmRZ0kPCYHsbMB4jtK+SWNq3HcvVf074+TTHnsPD1SlilWaUZKn7dPAb0opDfygtZ4N1Ndax5hevwjUz+9ApdQYYAxA48aNSyNWcQv7Tl/mpRXHiE1OZ2yvZky8u6XRPiwrHf74Cv78BuyrwoMzoePwInc/ycrNYmvEVuYFz+NkwkncqrnxUqeXGNF2BA6VbW8UEB0dDchzntaQk5RExqlTZISfJP3ECbLj40kPDCT70qW/97Fzc8PB3Z3aT47EqX17qnbtil2tWlaM2nZI8rR9t2uto5VS9YBtSqnQvC9qrbUpsf6LKdHOBvD39893H1E60jJz+GxrKAv2ReLpWo1VY7vh71nbePH07/DLG8bjJ+0eNppUuxTtXmBadhprTq5hYfBCLly7QIuaLfjk9k/o37Q/9pWkw0lFprUm6+xZkrZtIyM0jMzzUWRGniU3MfHvfSq5uGDn6kpVf3+cOvjg6OWFo7c3laTyU4Ekedo4rXW06eslpdRaoAsQq5Ry01rHKKXcgEs3PYmwqqDoRF5eeYzw2BRG3NaYNwe0pVoVO4gNhm3vwqltUL0hPLoIvAYW6dyJGYksC13G0hNLSchIwLeeL291fYueHj2lw0kFo7OzjZqukZHGQp4ToeRcuUJWdDQ5pkRp7+GBfYMGuNz3/+3deXhV9Z348ffn7tlDFkLIThLC5oYICOKOFdcZtSPo41hr63ScLs5Mx+q0/Y06Y1vn16f9tfP0N+pPbStUQbEouKBWUetoEZE1+0b2kIUQDOSu+f7+OAcMCmpYcnPD5/U857nnfu+5934/eU7yyTnne76fK3BNysZTHTPXhwAAGHNJREFUVIivrAx3Xt6ozMoznmjyHMNEJAFwGGM+ttcvAx4A1gK3Aj+zH1+IXi/V0XzsD/HTV6p4amMzE5O8/O62c7iwbKI1ifvLD1iDgrxJcOn9MP/OEQ0I6tzfyZMVT7K6ZjWD4UEuyL2Ar8/6OrOzZp/EiNRYYIwhsncvoeZmAnV1+KuqOfDBB4Ta2hiyryHjduMtLcGVkYHvtNPwlk0lcdEiPHl50e38OKLJc2zLAtbY/xG6gKeMMetFZBPwjIjcDjQBfxPFPqojeL++l7uf20Zb3yC3zC/grktLSU/wQPkaa7KD/haYcztc/COIT/vSn1veW84j2x5hQ8sGnOLkiqIruG3WbZROGPmgIjW2Dfn9+CsqCO5qItTRTqCqGn9NNeH2jkPVQgDE4yF+7lzizjyT+HPOwVtagic//4RXEVGH0+Q5hhljGoAzjtDeC1wy+j1SX2QgEOZ/r6/iyb80UZAWz4rb57GgJAP6dsGT34XGt62SYbe9AgULvtRnRoYibOvexmM7HuPPbX8myZPEN0/7JtdPvT7mp9DL0yMhTDhMsLHROtVaUWlNV1deftjAHQBPQQHe0lKSL7sMV0YG7txcvKWluLOzT0rVEPX5NHkqdYK8W9vD3au30bHPz7K5+fzoyunEDx2AP90P7/0aXD7rFO2C73ypSdw/PXI21ZvK92Z/j6VlS6M6scGJdCqVIjORiDX7zs6d+KtrCHd3E+poZ3DzR5hgEADx+fDk5RI/bx6ewgK8U6fiLSnBnZ2Nw+eLcgRqOE2eSh2nff4QP3+1miffbyJ3Qhyrv3UuZ+elwo5n4bUfwf4uOH0pXPJjSMn9ws/zh/2srV/LEzufoG2gjVRvKvfOvZe/Kvkr4t3jK9ns27cPGD9FsYf8foJNTYRaWwnU1ROorSXU2kqwrZVI395D90ricuHKyMCVmUnK9dcRd/oZ+GbOwFtcjDiPrzqOGh2aPJU6Dm/XdHPPc9vp6Pdz45w87rtmJnE92+GJG6H1A8g5G25aaT1+gUAkwOqa1Ty+43G6B7uZmT7TGjmbs2jcjoTs6LBuV46l5HlwwE64qxt/ZQX+8gqCTbsI1NYR7uy0CpTb3JMn487NJfH883GlZ+DOy7VuAyktjcn5XNUnNHkqdQz27A/y0CtVrPqwhSkZCay5cwFnTQjC+rvgoychYSJc+xvriNP5+b9mB0IHeGzHY6ypW0PPYA9zsubw0PkPMSdrzrhNmrHAhEKE9+wh3NGBv7LSKsjc0IC/pubweyTj43Hn5RE/Zw6e/Hw8U4rw5OXhKSyMar1JdXJp8lRqBIwxvLi9g39bW07/YIhvXVDMXRcV4tvyOKz4CYT9MPfv4KJ7Ie7zZ2JpH2jn6aqnea72OT4OfszCnIU8OONBFkz+cgOJ1IlhIhFCHZ0EamqsclnVNfZk5w2YQODQds6UFNyFBSRffjneKUU4MzLwFhXhnTbtlJuaTmnyVOpL69sf5O7ntvN6xW5Oy0nhD9+Yx/SBjfDY31qzAxUugiUPQdbMo36GMYat3VtZXrGcN5rfQBAWFyzmpuk3cdbEs0YxmlPPUDBoX4NsI9zTzYEPP7SqgTQ2HhqwA+DMyMBXVkaCPWjHNTEL79SpuHMm65kAdYgmT6W+gDGGZze38tOXKxkIhPnXK6Zxe1kI5xvfhJr1kFYMS5+CsiuOOhdtKBLi1aZXWVGxgvLecpI9yXxt5tdYNm0ZkxImjXJE45sJBgl1dhKoqyPY1Eygutq6FaS6GuP3H9rONXEivunTSViwAE9RId6SUjxFhTp3q/pSNHkq9Tna9w7y4+d38kZVF3ML03jgsmym7VoBj/7KuvVk8QMw7++POjtQn7+PZ2ueZWXVSroHuylMLuTH83/MVVOuGncjZ49FQUHBMb1vaHCQUHs7gdo6azq68p0EGhoJ9/QwtG/fYYN2XJmZeKZMIfWrXyX+7Nl48vNxZmTgysjQ063qmGnyVOoIguEhfvdeI798vRYRuOfyMu5IfBfHM0vBv9eawP3yn0Fi5hHfX7+3nuUVy3mx4UUCkQALJy/k/gX3szBnoc45O4zvC+5djAwMEGxqIlBVRaChgUBlJYH6BsK7dx+2naewEE9JMQnz5uFMTcWdk4OnqEiPJNVJo8lTqU/Z2NDLD5/fSV3XAJdMm8hPzhkka+O3ofl9yD/Xuq6Z/ZmJnzDG8JeOv7CicgXvtL6Dz+njmuJruHn6zRSnFkchkrGvr6+PSFcXCcEgobY2a9DOriaCzc0EGxoYOnDg0Lbi8eAtKSF+7ly8U4qsa5HTyvDk5emoVjXqNHkqZesZCHD/ugrWbWsnLy2Op/46nQUtD8Ozq61bT676JZx1CzgPnwrNH/bzcuPLLK9YTt3eOtJ8adx5xp0sm7aMVF9qlKIZe4YCAUJtbQQbGjiwaROBxkbq+/oY6t3D5PZ2ayOHA3d2Nu68PFJuuB5XRiae/Hy8ZVPx5OfrBAJqzNDkqU55/lCE3/7PLh5+u579gTD/siCZO8JP416/ElxeWPR9WPRP4Ek47H09gz2sql7FqqpV9AX6mJY2jf9Y+B8sKVoyJgtPj5ZIfz/BllaCu3YRqK5icPsOayq69vZDA3bE68VTPMW61WPxYnKLi3FnZ+MpKcGhkweoGKDJU53S3q/v5Z4/bqep9wBXl/q4P3U9aduWWwNO5v0dnPePkDjxsPfs7NnJEzufYEPzBsImzEV5F3HLjFtOmUkNTCTC0McfE/n4YwL19QQbGgk01BPp3UOguprQwaNIALcbX1mZXRLrPHyzZuHOycU3cwYOr5dQdTUASWVlUYpGqWOjyVOdknoGAjywroK129opThHenr+ZgurfQuteOOMmOO8uyPikzFdkKMJbLW+xvHI5m3dvJtmTzM3Tb+arZV+lIPnYRozGgiG/n0BVFf7qGgLV1QRqahgsL8cMDh62nTMtDVdmJt6yMibcfBOeggLc9iw7Dq83Sr1X6uTR5KlOKZEhw1Mbm/j5azWEggEen7GNizueQLb2QsliuPQ+mDTr0Pb7gvtYU7uGp6uepm2gjckJk/nns/+ZG6beMG4qm5hQyCqDVVFBoKaWcE8Pgdpags3N1m0fNvH58JaUkHrddXjy83AkJlmVP0pKcKakRDECpUafJk91ytjS3Me/rtlJZUc/d02u5M7wcjwNTdbMQBf/GPLnHdq2vLecZ6qfYV39OkJDIc7OOpvvz/k+F+ZdiMsRm782Jhw+dOQYqK4h2NREuLOTwK5dcLC4stuNKy0NT0EBKVddhSszA09xMb6yMtz5+Sf8tHRRUdEJ/TylRkts/hVQagRa9hzgl6/X8MctbSxObGRFzh9J790MmdNh2UqYejmIsD+0n7da3uLpqqfZ1r2NOFccV025imXTljE9fXq0w/jSgi0tBOrqCHd346+oINzVTaC+jlBT86FtHPHxuAsKcOfnk3jB+XiKS/BNn4a3tHRUR7R6dHCQilGaPNW4dSAY5ldv1PLke02caSrZkPUKRf0bwZ8JV/4CZt+KcTjZ2r2VZ6qf4U9Nf8If8VOQXMAPzvkB15ZcS5InKdphHJExhnBnJ4M7d+IvLyfU3EKos5NgczORnp5D2zmSk3FnZeGdUkzKVVfjKcgn7vTTcRcUjInBTXv27AEgLS0tyj1RamQ0eapxxxjDSzs6+MmLFRQObGZtykuUDm6DUIY1nd4532DvUIiXalaxqnoVjf2NJLoTuab4Gr5S+BXmTJozZmYBMqEQgzt2MLhtO6GOdmtka3094Z6eT061Op3WvZE5OSQuXIhv1iziTj8N54QJuPPyxkSSPJru7m5Ak6eKPZo81bgRGTK8Wt7Jf79Vj7t9E/+V8AJne7aAKxsu/xlDZ93Cpj3lrNn477y+63WCQ0FKJ5Ry37n3saRoSVTnmjWhEMGWVgJVlQRb2wi1NHNg80eH3xsZF4cnN5f4c+bgzsrCPXky3rIyfDNn6ohWpUaZJk8V84LhIZ7f0sajb9eQuWcz98etY7Z3O8aTDhc/yK6yxaxuWMdLL1xNz2APSe4kriu9jhum3kBZ2ujdX2hCIYJNTfirqwl3dhLq6CTc20OouQV/dTWEw4e2daak4DvzDBIXnUfcWbOJnzcXZ2rqmD6KVOpUoslTxawDwTBPf9DCynd2MG//m/zeu54cTwcmLov98/+NNzPzWdf0Gu+/+AgucXFe7nksKVzCxfkX43N9/oTkx2rI7ye8ezfhnh5C7R0E6usI7mqyKoBUVR1WN9KRmIgrPR1Xdjbpt30NT3Ex3pJSvEWFOBISjv4lSqmo0+SpYk5T735e2NrO++++wdWhV1nn/h987gChibN4b/oynh/q562mlQzWD5IVn8W3z/w210+9noy4jOP+bmMMxu8n3LuHQF0twbo6gs0thDo6iPT24q+t/eRaJIDLZU07l59P6tIb8U2bjm/mDNyTJ+NITNQjSaVilCZPFRMGgxHW72znw41/Jr3tDZY4PuC7jmY64uN5p+QC3kxJ492+cvp3rSbOFcfVU67m6uKrOT3z9BEP/okM7Cfc3UV4d5d1u0dlJaH2dsI93QTr6ons3XvY9s4JE3BPnowzM4O0efPwlpbiyszEPSkLd36+Xo/8HMXFWm1GxSZNnmrMau07wNvlTXTt2EBSx3ucx1aWOFt5P9nHhrRCfpo8jy2DHTBYRcpQChfkXsCFeReyKGfR556WNaEQ4e5uIvv2WfdEVlYRbGoi1NpKqKuLcEfHYduL2407NxdXejqJl1yMp7AQZ2oq3ilT8JaWajms4+By6Z8gFZt0z1VjRu9AgO31bbTVfEig4T3yBz7ibG8Vu7xOyjO83JeYRoUzDwPAfsp8uXxn2g3Mz57P9LTpuO1SYSYSIdjaSqSvj1B7B8HGBkLtHYRaWwjt7iLY2AhDQ5988bAyWAlzz8FTWIh78mRcWVk409LwFhUhbveRuqyOU29vLwDp6elR7olSI6PJM0aJyOXArwAn8Jgx5mdR7tKI+INhWpob2N1YTnfDRnr6NxGU3Thc++hwO6lLdVM70YPfkQWAS5zMjivlH1LPYGZcEdOGJuLs7CX4UgPhPSvo2NfPUP8+Qrt3E+7qgkjksO9zpqXhzs3FU1RI0qWX4s6ZjDMlFfekLLxlZTh8J2cAkfp8PfaEDpo8VazR5BmDRMQJ/AZYDLQCm0RkrTGmIqodM4bBAwPs6+9l30Ave7qb2Lunlf49zezv78A/2MeBQC+h8H5MJMiAgX7jJBxxkOCH+ADEBRPJ8bs4J5RASsRHcsCBZyCAo38AE9gObAeg2/5KiYvDlZ6OMyUFR3ISCXPn4sqehDsnB1d6Bq6siXgLdfSqUurE0uQZm+YCdcaYBgARWQlcC5zw5Ln2ilkk740ghsMX+GybAecQuMLgikAy1nJkw+dPHXYK1eXCmZKMKy0NR3IyzqwknKmpONOtkleOhAQcvjhcWRNxT5o05mfQUUqNT5o8Y1MO0DLseSsw79MbicgdwB0A+fn5x/RFgxPiiLgCIGBEjvAoGMF6dDjA4cTh8SJuDw5vPN74JOKTM0hNzyYhaQKpiRn4klIRrxeH14sjPh7x+XAkJuJMSUE8Hk2GSqkxT5PnOGaMeRR4FGDOnDnmWD7jxj9sOqF9Ukqp8UCTZ2xqA/KGPc+125SKKaWlpdHuglLHZGyUjlAjtQkoFZEiEfEAS4G1Ue6TUiPmcDhwOPTPkIo9euQZg4wxYRH5NvAq1sibJ4wx5VHullIjdrAkWWZmZpR7otTIaPKMUcaYl4GXo90PpY7HwWLYmjxVrNHzJUoppdQIafJUSimlRkiTp1JKKTVCmjyVUkqpERJjjuneeRVjRKQbaDrGt2cAPSewO9E0XmIZL3GAxjJWjZdYjjeOAmPMZ0a0afJUX0hEPjTGzIl2P06E8RLLeIkDNJaxarzEcrLi0NO2Siml1Ahp8lRKKaVGSJOn+jIejXYHTqDxEst4iQM0lrFqvMRyUuLQa55KKaXUCOmRp1JKKTVCmjyVUkqpEdLkqY5KRC4XkWoRqRORe6LdnyMRkSdEpEtEdg5rSxOR10Wk1n6cYLeLiPzajme7iMwe9p5b7e1rReTWKMWSJyIbRKRCRMpF5HuxGI+I+ETkAxHZZsdxv91eJCIb7f6ussvpISJe+3md/XrhsM+6126vFpGvjGYcw4mIU0S2iMiL9vOYjEVEdonIDhHZKiIf2m0xtX8N60OqiKwWkSoRqRSRc0c1FmOMLrp8ZsEqdVYPTAE8wDZgRrT7dYR+ng/MBnYOa/tP4B57/R7gIXv9CuAVQID5wEa7PQ1osB8n2OsTohBLNjDbXk8CaoAZsRaP3Z9Ee90NbLT79wyw1G5/GPh7e/1O4GF7fSmwyl6fYe93XqDI3h+dUdrP/gl4CnjRfh6TsQC7gIxPtcXU/jWs378HvmGve4DU0Yxl1HdCXWJjAc4FXh32/F7g3mj36yh9LeTw5FkNZNvr2UC1vf4IsOzT2wHLgEeGtR+2XRTjegFYHMvxAPHAR8A8rFleXJ/ev7Dq0p5rr7vs7eTT+9zw7UY5hlzgDeBi4EW7b7Eayy4+mzxjbv8CUoBG7EGv0YhFT9uqo8kBWoY9b7XbYkGWMabDXu8Esuz1o8U05mK1T/edhXXUFnPx2Kc5twJdwOtYR1p7jTHhI/TpUH/t1/uBdMZAHLb/A9wNDNnP04ndWAzwmohsFpE77LaY27+wjt67gd/ap9MfE5EERjEWTZ5qXDPWv5MxdT+WiCQCzwF3GWP2DX8tVuIxxkSMMWdiHbXNBaZFuUvHRESuArqMMZuj3ZcT5DxjzGxgCfAPInL+8BdjZf/COqqfDfy3MeYsYD/WadpDTnYsmjzV0bQBecOe59ptsWC3iGQD2I9ddvvRYhozsYqIGytx/sEY80e7OWbjMcbsBTZgndpMFRHXEfp0qL/26ylAL2MjjoXANSKyC1iJder2V8RmLBhj2uzHLmAN1j82sbh/tQKtxpiN9vPVWMl01GLR5KmOZhNQao8q9GANflgb5T59WWuBg6PmbsW6dniw/W/tkXfzgX77FM+rwGUiMsEenXeZ3TaqRESAx4FKY8wvhr0UU/GISKaIpNrrcVjXbSuxkugNR4njYHw3AG/aRw1rgaX2CNYioBT4YHSisBhj7jXG5BpjCrF+B940xtxMDMYiIgkiknRwHWu/2EmM7V8AxphOoEVEyuymS4AKRjOW0b5grUvsLFgj1Gqwrlf9MNr9OUofnwY6gBDWf6O3Y11jegOoBf4EpNnbCvAbO54dwJxhn/N1oM5ebotSLOdhnWbaDmy1lytiLR7gdGCLHcdO4H/Z7VOwEkYd8Czgtdt99vM6+/Upwz7rh3Z81cCSKO9rF/LJaNuYi8Xu8zZ7KT/4Ox1r+9ewPpwJfGjvZ89jjZYdtVh0ej6llFJqhPS0rVJKKTVCmjyVUkqpEdLkqZRSSo2QJk+llFJqhDR5KqWUUiOkyVMpdUQikm5X39gqIp0i0mavD4jI/z2J33uhiCw4WZ+v1Ing+uJNlFKnImNML9a9dIjIfcCAMebno/DVFwIDwHuj8F1KHRM98lRKjYh9ZHiwruV9IvJ7EfmziDSJyHUi8p9i1Yxcb083iIicLSJv2xOSvzpsCrXvilW/dLuIrLQnxP8W8I/2Ue4ie8ai50Rkk70sHPbdy0XkfbsW4zft9mwRecd+/04RWRSNn5Ma3/TIUyl1vIqBi7BqVr4PXG+MuVtE1gBXishLwH8B1xpjukXkRuBBrJld7gGKjDEBEUk1xuwVkYcZdpQrIk8BvzTGvCsi+VjTp023v/t0rPqMCcAW+7uWYZUIe1BEnFhl0ZQ6oTR5KqWO1yvGmJCI7MAqor7ebt+BVWu1DJgFvG5N34sTa0pFsKZW+4OIPI81xdqRXArMsN8LkGxXngF4wRgzCAyKyAasic43AU/YR73PG2O2npgwlfqEJk+l1PEKABhjhkQkZD6Z83MI62+MAOXGmHOP8N4rgfOBq4EfishpR9jGAcw3xviHN9rJ9NPzixpjzDtildq6EvidiPzCGPPkMcam1BHpNU+l1MlWDWSKyLlglV0TkZki4gDyjDEbgB9gle9KBD4Gkoa9/zXgOwefiMiZw167VkR8IpKONdBok4gUALuNMf8PeAyrVJVSJ5QmT6XUSWWMCWKV53pIRLZhVYtZgHX6doV9uncL8Gtj1f9cB/z1wQFDwHeBOfagogqsAUUHbccqD/YX4N+NMe1YSXSbiGwBbsSqv6nUCaVVVZRSMWmUb59R6jB65KmUUkqNkB55KqWUUiOkR55KKaXUCGnyVEoppUZIk6dSSik1Qpo8lVJKqRHS5KmUUkqN0P8HVpPJsMV8fSkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "7587c4a396d64d011ff5d8cf0f755f43",
          "grade": false,
          "grade_id": "cell-75b928a3930343ef",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "EI8qMYVLAMs3"
      },
      "source": [
        "What do you observe?\n",
        "\n",
        "Increasing the exploration via the $\\epsilon$-greedy strategy does not seem to be helping. In fact, the agent's cumulative reward decreases because it is spending more and more time trying out the exploratory actions.\n",
        "\n",
        "Can we do better...? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "fea0fa31931e764395600778cacbde8d",
          "grade": false,
          "grade_id": "cell-53c7b261289030c7",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "Q8yJVsiHAMs3"
      },
      "source": [
        "## Section 2: Dyna-Q+"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "c201b6bae38cb088c3c3cbc51810c914",
          "grade": false,
          "grade_id": "cell-1ed17a58ff98db6f",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "3lU6LYntAMs3"
      },
      "source": [
        "The motivation behind Dyna-Q+ is to give a bonus reward for actions that haven't been tried for a long time, since there is a greater chance that the dynamics for that actions might have changed.\n",
        "\n",
        "In particular, if the modeled reward for a transition is $r$, and the transition has not been tried in $\\tau(s,a)$ time steps, then planning updates are done as if that transition produced a reward of $r + \\kappa \\sqrt{ \\tau(s,a)}$, for some small $\\kappa$. \n",
        "\n",
        "Let's implement that!\n",
        "\n",
        "Based on your `DynaQAgent`, create a new class `DynaQPlusAgent` to implement the aforementioned exploration heuristic. Additionally :\n",
        "1. actions that had never been tried before from a state should now be allowed to be considered in the planning step,\n",
        "2. and the initial model for such actions is that they lead back to the same state with a reward of zero.\n",
        "\n",
        "At this point, you might want to refer to the video lectures and [Section 8.3](http://www.incompleteideas.net/book/RLbook2018.pdf#page=188) of the RL textbook for a refresher on Dyna-Q+."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "ebbfc778eab63bdff736bc478ebc5928",
          "grade": false,
          "grade_id": "cell-ede9dc6883c45c67",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "NMbYg9I9AMs4"
      },
      "source": [
        "As usual, let's break this down in pieces and do it one-by-one.\n",
        "\n",
        "First of all, check out the `agent_init` method below. In particular, pay attention to the attributes which are new to `DynaQPlusAgent`– state-visitation counts $\\tau$ and the scaling parameter $\\kappa$ – because you shall be using them later. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "53479b7ba60db3596b74755d1319b574",
          "grade": false,
          "grade_id": "cell-45b5c95ae385f669",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "AZF4hgFcAMs4"
      },
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "class DynaQPlusAgent(BaseAgent):\n",
        "    \n",
        "    def agent_init(self, agent_info):\n",
        "        \"\"\"Setup for the agent called when the experiment first starts.\n",
        "\n",
        "        Args:\n",
        "            agent_init_info (dict), the parameters used to initialize the agent. The dictionary contains:\n",
        "            {\n",
        "                num_states (int): The number of states,\n",
        "                num_actions (int): The number of actions,\n",
        "                epsilon (float): The parameter for epsilon-greedy exploration,\n",
        "                step_size (float): The step-size,\n",
        "                discount (float): The discount factor,\n",
        "                planning_steps (int): The number of planning steps per environmental interaction\n",
        "                kappa (float): The scaling factor for the reward bonus\n",
        "\n",
        "                random_seed (int): the seed for the RNG used in epsilon-greedy\n",
        "                planning_random_seed (int): the seed for the RNG used in the planner\n",
        "            }\n",
        "        \"\"\"\n",
        "\n",
        "        # First, we get the relevant information from agent_info \n",
        "        # Note: we use np.random.RandomState(seed) to set the two different RNGs\n",
        "        # for the planner and the rest of the code\n",
        "        try:\n",
        "            self.num_states = agent_info[\"num_states\"]\n",
        "            self.num_actions = agent_info[\"num_actions\"]\n",
        "        except:\n",
        "            print(\"You need to pass both 'num_states' and 'num_actions' \\\n",
        "                   in agent_info to initialize the action-value table\")\n",
        "        self.gamma = agent_info.get(\"discount\", 0.95)\n",
        "        self.step_size = agent_info.get(\"step_size\", 0.1)\n",
        "        self.epsilon = agent_info.get(\"epsilon\", 0.1)\n",
        "        self.planning_steps = agent_info.get(\"planning_steps\", 10)\n",
        "        self.kappa = agent_info.get(\"kappa\", 0.001)\n",
        "\n",
        "        self.rand_generator = np.random.RandomState(agent_info.get('random_seed', 42))\n",
        "        self.planning_rand_generator = np.random.RandomState(agent_info.get('planning_random_seed', 42))\n",
        "\n",
        "        # Next, we initialize the attributes required by the agent, e.g., q_values, model, tau, etc.\n",
        "        # The visitation-counts can be stored as a table as well, like the action values \n",
        "        self.q_values = np.zeros((self.num_states, self.num_actions))\n",
        "        self.tau = np.zeros((self.num_states, self.num_actions))\n",
        "        self.actions = list(range(self.num_actions))\n",
        "        self.past_action = -1\n",
        "        self.past_state = -1\n",
        "        self.model = {}"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "ae86189d377dcbeb226bd8f01839be62",
          "grade": false,
          "grade_id": "cell-38c00ecba461bf92",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "rGdgSBv5AMs4"
      },
      "source": [
        "Now first up, implement the `update_model` method. Note that this is different from Dyna-Q in the aforementioned way.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "977dc282839bdb10b454c2ff698b58e6",
          "grade": false,
          "grade_id": "cell-b65a5bb0b37ceb84",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "Qu00UZjwAMs4"
      },
      "source": [
        "%%add_to DynaQPlusAgent\n",
        "\n",
        "# [GRADED]\n",
        "\n",
        "def update_model(self, past_state, past_action, state, reward):\n",
        "    \"\"\"updates the model \n",
        "\n",
        "    Args:\n",
        "        past_state  (int): s\n",
        "        past_action (int): a\n",
        "        state       (int): s'\n",
        "        reward      (int): r\n",
        "    Returns:\n",
        "        Nothing\n",
        "    \"\"\"\n",
        "\n",
        "    # Recall that when adding a state-action to the model, if the agent is visiting the state\n",
        "    #    for the first time, then the remaining actions need to be added to the model as well\n",
        "    #    with zero reward and a transition into itself. Something like:\n",
        "    ##   for action in self.actions:\n",
        "    ##       if action != past_action:\n",
        "    ##           self.model[past_state][action] = (past_state, 0)  \n",
        "    #\n",
        "    # Note: do *not* update the visitation-counts here. We will do that in `agent_step`.\n",
        "    #\n",
        "    # (3 lines)\n",
        "\n",
        "    if past_state not in self.model:\n",
        "        self.model[past_state] = {past_action : (state, reward)}\n",
        "        ### START CODE HERE ###\n",
        "        for action in self.actions:\n",
        "            if action != past_action:\n",
        "                self.model[past_state][action] = (past_state, 0)\n",
        "        ### END CODE HERE ###\n",
        "    else:\n",
        "        self.model[past_state][past_action] = (state, reward)\n",
        "    "
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "b319274d17d4f236253245cbafc2f2c9",
          "grade": false,
          "grade_id": "cell-817a09952176290c",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "jP8-jsuAAMs5"
      },
      "source": [
        "### Test `update_model()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "b51603111ba2020112cbdcc427c225b0",
          "grade": true,
          "grade_id": "DynaQPlus_update_model",
          "locked": true,
          "points": 5,
          "schema_version": 1,
          "solution": false
        },
        "id": "f-o8WKxjAMs5",
        "outputId": "d65bfaac-a278-4fa2-c378-cc01eb0a18ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "## Test code for update_model() ##\n",
        "\n",
        "actions = []\n",
        "agent_info = {\"num_actions\": 4, \n",
        "              \"num_states\": 3, \n",
        "              \"epsilon\": 0.1, \n",
        "              \"step_size\": 0.1, \n",
        "              \"discount\": 1.0, \n",
        "              \"random_seed\": 0,\n",
        "              \"planning_random_seed\": 0}\n",
        "test_agent = DynaQPlusAgent()\n",
        "test_agent.agent_init(agent_info)\n",
        "test_agent.update_model(0,2,0,1)\n",
        "test_agent.update_model(2,0,1,1)\n",
        "test_agent.update_model(0,3,1,2)\n",
        "test_agent.tau[0][0] += 1\n",
        "print(\"Model: \\n\", test_agent.model)\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \n",
            " {0: {2: (0, 1), 0: (0, 0), 1: (0, 0), 3: (1, 2)}, 2: {0: (1, 1), 1: (2, 0), 2: (2, 0), 3: (2, 0)}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "d5fac20afac86a10733c1eff19544eec",
          "grade": false,
          "grade_id": "cell-7d4bca62495646a5",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "1qv8XAWTAMs5"
      },
      "source": [
        "Expected output:\n",
        "```\n",
        "Model: \n",
        " {0: {2: (0, 1), 0: (0, 0), 1: (0, 0), 3: (1, 2)}, 2: {0: (1, 1), 1: (2, 0), 2: (2, 0), 3: (2, 0)}}\n",
        "```\n",
        "Note that the actions that were not taken from a state are also added to the model, with a loop back into the same state with a reward of 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "a7bc69509a63b874bea41e9e1dacddeb",
          "grade": false,
          "grade_id": "cell-d16ba2244f70cccc",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "3eCSsYNNAMs5"
      },
      "source": [
        "Next, you will implement the `planning_step()` method. This will be very similar to the one you implemented in `DynaQAgent`, but here you will be adding the exploration bonus to the reward in the simulated transition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "0527e2f3bdd38392222bcaab60b86473",
          "grade": false,
          "grade_id": "cell-850b98235b2087aa",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "i4_OWOSKAMs6"
      },
      "source": [
        "%%add_to DynaQPlusAgent\n",
        "\n",
        "# [GRADED]\n",
        "\n",
        "def planning_step(self):\n",
        "    \"\"\"performs planning, i.e. indirect RL.\n",
        "\n",
        "    Args:\n",
        "        None\n",
        "    Returns:\n",
        "        Nothing\n",
        "    \"\"\"\n",
        "    \n",
        "    # The indirect RL step:\n",
        "    # - Choose a state and action from the set of experiences that are stored in the model. (~2 lines)\n",
        "    # - Query the model with this state-action pair for the predicted next state and reward.(~1 line)\n",
        "    # - **Add the bonus to the reward** (~1 line)\n",
        "    # - Update the action values with this simulated experience.                            (2~4 lines)\n",
        "    # - Repeat for the required number of planning steps.\n",
        "    #\n",
        "    # Note that the update equation is different for terminal and non-terminal transitions. \n",
        "    # To differentiate between a terminal and a non-terminal next state, assume that the model stores\n",
        "    # the terminal state as a dummy state like -1\n",
        "    #\n",
        "    # Important: remember you have a random number generator 'planning_rand_generator' as \n",
        "    #     a part of the class which you need to use as self.planning_rand_generator.choice()\n",
        "    #     For the sake of reproducibility and grading, *do not* use anything else like \n",
        "    #     np.random.choice() for performing search control.\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    for i in range(self.planning_steps):\n",
        "        past_state = self.planning_rand_generator.choice(list(self.model.keys()))\n",
        "        past_action = self.planning_rand_generator.choice(list(self.model[past_state].keys()))\n",
        "        next_state, reward = self.model[past_state][past_action]\n",
        "        reward=reward+self.kappa*np.sqrt(self.tau[past_state][past_action])\n",
        "        if next_state == -1:\n",
        "            q_max = 0\n",
        "        else:\n",
        "            q_max = np.max(self.q_values[next_state])\n",
        "        self.q_values[past_state, past_action] += self.step_size * (reward + self.gamma * q_max - self.q_values[past_state, past_action])\n",
        "      \n",
        "    ### END CODE HERE ###"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "d62d53a3b16a0a7fa4842f5775c442c2",
          "grade": false,
          "grade_id": "cell-f03c6dd8052fd06c",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "En32M87jAMs6"
      },
      "source": [
        "### Test `planning_step()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "cdcaeef389cd61190d8c59f094144fbf",
          "grade": true,
          "grade_id": "DynaQPlus_planning_step",
          "locked": true,
          "points": 5,
          "schema_version": 1,
          "solution": false
        },
        "id": "qOK9D-xKAMs6",
        "outputId": "86ecb260-f6bc-4eb7-c270-71c66c899eb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "## Test code for planning_step() ##\n",
        "\n",
        "actions = []\n",
        "agent_info = {\"num_actions\": 4, \n",
        "              \"num_states\": 3, \n",
        "              \"epsilon\": 0.1, \n",
        "              \"step_size\": 0.1, \n",
        "              \"discount\": 1.0, \n",
        "              \"kappa\": 0.001,\n",
        "              \"planning_steps\": 4,\n",
        "              \"random_seed\": 0,\n",
        "              \"planning_random_seed\": 1}\n",
        "test_agent = DynaQPlusAgent()\n",
        "test_agent.agent_init(agent_info)\n",
        "test_agent.update_model(0,1,-1,1)\n",
        "test_agent.tau += 1; test_agent.tau[0][1] = 0\n",
        "test_agent.update_model(0,2,1,1)\n",
        "test_agent.tau += 1; test_agent.tau[0][2] = 0    # Note that these counts are manually updated \n",
        "test_agent.update_model(2,0,1,1)                 #     as we'll code them in `agent_step'  \n",
        "test_agent.tau += 1; test_agent.tau[2][0] = 0    #     which hasn't been implemented yet.\n",
        "\n",
        "test_agent.planning_step()\n",
        "\n",
        "print(\"Model: \\n\", test_agent.model)\n",
        "print(\"Action-value estimates: \\n\", test_agent.q_values)\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \n",
            " {0: {1: (-1, 1), 0: (0, 0), 2: (1, 1), 3: (0, 0)}, 2: {0: (1, 1), 1: (2, 0), 2: (2, 0), 3: (2, 0)}}\n",
            "Action-value estimates: \n",
            " [[0.         0.10014142 0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.00036373 0.         0.00017321]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "bc713c424acb265ebef08b7c5d2321e8",
          "grade": false,
          "grade_id": "cell-c624d442e2ae7d30",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "rsQz0PG7AMs7"
      },
      "source": [
        "Expected output:\n",
        "```\n",
        "Model: \n",
        " {0: {1: (-1, 1), 0: (0, 0), 2: (1, 1), 3: (0, 0)}, 2: {0: (1, 1), 1: (2, 0), 2: (2, 0), 3: (2, 0)}}\n",
        "Action-value estimates: \n",
        " [[0.         0.10014142 0.         0.        ]\n",
        " [0.         0.         0.         0.        ]\n",
        " [0.         0.00036373 0.         0.00017321]]\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "45628d99c845d3b4f280c006e697799d",
          "grade": false,
          "grade_id": "cell-92d49553185d7c50",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "PnR9lyaZAMs7"
      },
      "source": [
        "Again, before you move on to implement the rest of the agent methods, here are the couple of helper functions that you've used in the previous assessments for choosing an action using an $\\epsilon$-greedy policy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "4ae83584fd55c126c09c1c43173dcbaf",
          "grade": false,
          "grade_id": "cell-c31cab304f2230ae",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "BId8uDfgAMs7"
      },
      "source": [
        "%%add_to DynaQPlusAgent\n",
        "\n",
        "# Do not modify this cell!\n",
        "\n",
        "def argmax(self, q_values):\n",
        "    \"\"\"argmax with random tie-breaking\n",
        "    Args:\n",
        "        q_values (Numpy array): the array of action values\n",
        "    Returns:\n",
        "        action (int): an action with the highest value\n",
        "    \"\"\"\n",
        "    top = float(\"-inf\")\n",
        "    ties = []\n",
        "\n",
        "    for i in range(len(q_values)):\n",
        "        if q_values[i] > top:\n",
        "            top = q_values[i]\n",
        "            ties = []\n",
        "\n",
        "        if q_values[i] == top:\n",
        "            ties.append(i)\n",
        "\n",
        "    return self.rand_generator.choice(ties)\n",
        "\n",
        "def choose_action_egreedy(self, state):\n",
        "    \"\"\"returns an action using an epsilon-greedy policy w.r.t. the current action-value function.\n",
        "\n",
        "    Important: assume you have a random number generator 'rand_generator' as a part of the class\n",
        "                which you can use as self.rand_generator.choice() or self.rand_generator.rand()\n",
        "\n",
        "    Args:\n",
        "        state (List): coordinates of the agent (two elements)\n",
        "    Returns:\n",
        "        The action taken w.r.t. the aforementioned epsilon-greedy policy\n",
        "    \"\"\"\n",
        "\n",
        "    if self.rand_generator.rand() < self.epsilon:\n",
        "        action = self.rand_generator.choice(self.actions)\n",
        "    else:\n",
        "        values = self.q_values[state]\n",
        "        action = self.argmax(values)\n",
        "\n",
        "    return action"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "ff01d8dc7e39cfc84ff1e0799736d5a3",
          "grade": false,
          "grade_id": "cell-2af006f875c70cf7",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "-Fyccfy8AMs8"
      },
      "source": [
        "Now implement the rest of the agent-related methods, namely `agent_start`, `agent_step`, and `agent_end`. Again, these will be very similar to the ones in the `DynaQAgent`, but you will have to think of a way to update the counts since the last visit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "2dff5e0b57e00801566b5b83956a18d6",
          "grade": false,
          "grade_id": "cell-34cb21ba9a8f931c",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "l9x-z4g3AMs8"
      },
      "source": [
        "%%add_to DynaQPlusAgent\n",
        "\n",
        "# [GRADED]\n",
        "    \n",
        "def agent_start(self, state):\n",
        "    \"\"\"The first method called when the experiment starts, called after\n",
        "    the environment starts.\n",
        "    Args:\n",
        "        state (Numpy array): the state from the\n",
        "            environment's env_start function.\n",
        "    Returns:\n",
        "        (int) The first action the agent takes.\n",
        "    \"\"\"\n",
        "    \n",
        "    # given the state, select the action using self.choose_action_egreedy(), \n",
        "    # and save current state and action (~2 lines)\n",
        "    ### self.past_state = ?\n",
        "    ### self.past_action = ?\n",
        "    # Note that the last-visit counts are not updated here.\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    self.past_state=state\n",
        "    self.past_action=self.choose_action_egreedy(state)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return self.past_action\n",
        "\n",
        "def agent_step(self, reward, state):\n",
        "    \"\"\"A step taken by the agent.\n",
        "    Args:\n",
        "        reward (float): the reward received for taking the last action taken\n",
        "        state (Numpy array): the state from the\n",
        "            environment's step based on where the agent ended up after the\n",
        "            last step\n",
        "    Returns:\n",
        "        (int) The action the agent is taking.\n",
        "    \"\"\"  \n",
        "    \n",
        "    # Update the last-visited counts (~2 lines)\n",
        "    # - Direct-RL step (1~3 lines)\n",
        "    # - Model Update step (~1 line)\n",
        "    # - `planning_step` (~1 line)\n",
        "    # - Action Selection step (~1 line)\n",
        "    # Save the current state and action before returning the action to be performed. (~2 lines)\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    self.tau+=1\n",
        "    self.tau[self.past_state][self.past_action]=0\n",
        "    q_max=np.max(self.q_values[state])\n",
        "    self.q_values[self.past_state, self.past_action] += self.step_size * (reward + self.gamma * q_max - self.q_values[self.past_state, self.past_action])\n",
        "    self.update_model(self.past_state,self.past_action,state,reward)\n",
        "    self.planning_step()\n",
        "    \n",
        "    self.past_state=state\n",
        "    self.past_action=self.choose_action_egreedy(state)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return self.past_action\n",
        "\n",
        "def agent_end(self, reward):\n",
        "    \"\"\"Called when the agent terminates.\n",
        "    Args:\n",
        "        reward (float): the reward the agent received for entering the\n",
        "            terminal state.\n",
        "    \"\"\"\n",
        "    # Again, add the same components you added in agent_step to augment Dyna-Q into Dyna-Q+\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    self.tau+=1\n",
        "    self.tau[self.past_state][self.past_action]=0\n",
        "    self.q_values[self.past_state, self.past_action] += self.step_size * (reward - self.q_values[self.past_state, self.past_action])\n",
        "    self.update_model(self.past_state,self.past_action,-1,reward)\n",
        "    self.planning_step()\n",
        "    ### END CODE HERE ###"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "0d0186afc16559c8d05fff29e5b91b50",
          "grade": false,
          "grade_id": "cell-da231fa8a614788e",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "SiSbbe4CAMs9"
      },
      "source": [
        "Let's test these methods one-by-one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "723356966ffc5fbeb16a6cd981071bbe",
          "grade": false,
          "grade_id": "cell-8db85fa89415ea0e",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "ElLDLTviAMs9"
      },
      "source": [
        "### Test `agent_start()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "703e7137c1d55bd3649a2cabe18f6738",
          "grade": true,
          "grade_id": "DynaPlus_agent_start",
          "locked": true,
          "points": 5,
          "schema_version": 1,
          "solution": false
        },
        "id": "F83dckZLAMs9",
        "outputId": "217df7d8-5b27-44dd-e0f5-3a7f33bd6f0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "## Test code for agent_start() ##\n",
        "\n",
        "agent_info = {\"num_actions\": 4, \n",
        "              \"num_states\": 3, \n",
        "              \"epsilon\": 0.1, \n",
        "              \"step_size\": 0.1, \n",
        "              \"discount\": 1.0,\n",
        "              \"kappa\": 0.001,\n",
        "              \"random_seed\": 0,\n",
        "              \"planning_random_seed\": 0}\n",
        "test_agent = DynaQPlusAgent()\n",
        "test_agent.agent_init(agent_info)\n",
        "action = test_agent.agent_start(0) # state\n",
        "print(\"Action:\", action)\n",
        "print(\"Timesteps since last visit: \\n\", test_agent.tau)\n",
        "print(\"Action-value estimates: \\n\", test_agent.q_values)\n",
        "print(\"Model: \\n\", test_agent.model)\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Action: 1\n",
            "Timesteps since last visit: \n",
            " [[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n",
            "Action-value estimates: \n",
            " [[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n",
            "Model: \n",
            " {}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "ea8c3a78e11dd96c73d1d02933e0ec64",
          "grade": false,
          "grade_id": "cell-f6fb327707c1855c",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "qnSsQx3lAMs9"
      },
      "source": [
        "Expected output:\n",
        "```\n",
        "Action: 1\n",
        "Timesteps since last visit: \n",
        " [[0. 0. 0. 0.]\n",
        " [0. 0. 0. 0.]\n",
        " [0. 0. 0. 0.]]\n",
        "Action-value estimates: \n",
        " [[0. 0. 0. 0.]\n",
        " [0. 0. 0. 0.]\n",
        " [0. 0. 0. 0.]]\n",
        "Model: \n",
        " {}\n",
        "```\n",
        "Remember the last-visit counts are not updated in `agent_start()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "28714342c4f7fec008e01c525e98d2a6",
          "grade": false,
          "grade_id": "cell-be8fc718581879ad",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "slfxx_UrAMs-"
      },
      "source": [
        "### Test `agent_step()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "1ebd676152a198dc5e4e009198c36aee",
          "grade": true,
          "grade_id": "DynaQPlus_agent_step",
          "locked": true,
          "points": 5,
          "schema_version": 1,
          "solution": false
        },
        "id": "WpNPS4Z4AMs-",
        "outputId": "ee7b9e08-dff7-40a9-db30-f8ba864b617c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "## Test code for agent_step() ##\n",
        "\n",
        "agent_info = {\"num_actions\": 4, \n",
        "              \"num_states\": 3, \n",
        "              \"epsilon\": 0.1, \n",
        "              \"step_size\": 0.1, \n",
        "              \"discount\": 1.0,\n",
        "              \"kappa\": 0.001,\n",
        "              \"planning_steps\": 4,\n",
        "              \"random_seed\": 0,\n",
        "              \"planning_random_seed\": 0}\n",
        "test_agent = DynaQPlusAgent()\n",
        "test_agent.agent_init(agent_info)\n",
        "actions = []\n",
        "actions.append(test_agent.agent_start(0))    # state\n",
        "actions.append(test_agent.agent_step(1,2))   # (reward, state)\n",
        "actions.append(test_agent.agent_step(0,1))   # (reward, state)\n",
        "print(\"Actions:\", actions)\n",
        "print(\"Timesteps since last visit: \\n\", test_agent.tau)\n",
        "print(\"Action-value estimates: \\n\", test_agent.q_values)\n",
        "print(\"Model: \\n\", test_agent.model)\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actions: [1, 3, 1]\n",
            "Timesteps since last visit: \n",
            " [[2. 1. 2. 2.]\n",
            " [2. 2. 2. 2.]\n",
            " [2. 2. 2. 0.]]\n",
            "Action-value estimates: \n",
            " [[1.91000000e-02 2.71000000e-01 0.00000000e+00 1.91000000e-02]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 1.83847763e-04 4.24264069e-04 0.00000000e+00]]\n",
            "Model: \n",
            " {0: {1: (2, 1), 0: (0, 0), 2: (0, 0), 3: (0, 0)}, 2: {3: (1, 0), 0: (2, 0), 1: (2, 0), 2: (2, 0)}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "b7f7f472dbae4f04ab045f9070443158",
          "grade": false,
          "grade_id": "cell-6cd0bcf30529fcca",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "f3PwUCxFAMs-"
      },
      "source": [
        "Expected output:\n",
        "```\n",
        "Actions: [1, 3, 1]\n",
        "Timesteps since last visit: \n",
        " [[2. 1. 2. 2.]\n",
        " [2. 2. 2. 2.]\n",
        " [2. 2. 2. 0.]]\n",
        "Action-value estimates: \n",
        " [[1.91000000e-02 2.71000000e-01 0.00000000e+00 1.91000000e-02]\n",
        " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
        " [0.00000000e+00 1.83847763e-04 4.24264069e-04 0.00000000e+00]]\n",
        "Model: \n",
        " {0: {1: (2, 1), 0: (0, 0), 2: (0, 0), 3: (0, 0)}, 2: {3: (1, 0), 0: (2, 0), 1: (2, 0), 2: (2, 0)}}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "069707871b3203dcaf81c9081726455b",
          "grade": false,
          "grade_id": "cell-ffbeb161866707da",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "QC9SxsRaAMs-"
      },
      "source": [
        "### Test `agent_end()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "cfdf00092d97d6e9ac98447202a6d292",
          "grade": true,
          "grade_id": "DynaQPlus_agent_end",
          "locked": true,
          "points": 5,
          "schema_version": 1,
          "solution": false
        },
        "id": "kPJLq_TjAMs_",
        "outputId": "b9c809e9-cb8d-4cf3-9bc6-82a7d16f379f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "## Test code for agent_end() ##\n",
        "\n",
        "agent_info = {\"num_actions\": 4, \n",
        "              \"num_states\": 3, \n",
        "              \"epsilon\": 0.1, \n",
        "              \"step_size\": 0.1, \n",
        "              \"discount\": 1.0,\n",
        "              \"kappa\": 0.001,\n",
        "              \"planning_steps\": 4,\n",
        "              \"random_seed\": 0,\n",
        "              \"planning_random_seed\": 0}\n",
        "test_agent = DynaQPlusAgent()\n",
        "test_agent.agent_init(agent_info)\n",
        "actions = []\n",
        "actions.append(test_agent.agent_start(0))\n",
        "actions.append(test_agent.agent_step(1,2))\n",
        "actions.append(test_agent.agent_step(0,1))\n",
        "test_agent.agent_end(1)\n",
        "print(\"Actions:\", actions)\n",
        "print(\"Timesteps since last visit: \\n\", test_agent.tau)\n",
        "print(\"Action-value estimates: \\n\", test_agent.q_values)\n",
        "print(\"Model: \\n\", test_agent.model)\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actions: [1, 3, 1]\n",
            "Timesteps since last visit: \n",
            " [[3. 2. 3. 3.]\n",
            " [3. 0. 3. 3.]\n",
            " [3. 3. 3. 1.]]\n",
            "Action-value estimates: \n",
            " [[1.91000000e-02 3.44083848e-01 0.00000000e+00 4.44632051e-02]\n",
            " [1.91732051e-02 1.90000000e-01 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 1.83847763e-04 4.24264069e-04 0.00000000e+00]]\n",
            "Model: \n",
            " {0: {1: (2, 1), 0: (0, 0), 2: (0, 0), 3: (0, 0)}, 2: {3: (1, 0), 0: (2, 0), 1: (2, 0), 2: (2, 0)}, 1: {1: (-1, 1), 0: (1, 0), 2: (1, 0), 3: (1, 0)}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "c008b44213589da78abaf90a07ebb93e",
          "grade": false,
          "grade_id": "cell-e4831f4d1cf10b12",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "gtP8PQAHAMs_"
      },
      "source": [
        "Expected output:\n",
        "```\n",
        "Actions: [1, 3, 1]\n",
        "Timesteps since last visit: \n",
        " [[3. 2. 3. 3.]\n",
        " [3. 0. 3. 3.]\n",
        " [3. 3. 3. 1.]]\n",
        "Action-value estimates: \n",
        " [[1.91000000e-02 3.44083848e-01 0.00000000e+00 4.44632051e-02]\n",
        " [1.91732051e-02 1.90000000e-01 0.00000000e+00 0.00000000e+00]\n",
        " [0.00000000e+00 1.83847763e-04 4.24264069e-04 0.00000000e+00]]\n",
        "Model: \n",
        " {0: {1: (2, 1), 0: (0, 0), 2: (0, 0), 3: (0, 0)}, 2: {3: (1, 0), 0: (2, 0), 1: (2, 0), 2: (2, 0)}, 1: {1: (-1, 1), 0: (1, 0), 2: (1, 0), 3: (1, 0)}}\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "334f1ceca4ab090a3e1ec653e3b496c2",
          "grade": false,
          "grade_id": "cell-839b7e5d8b7c439f",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "ivegFlUAAMs_"
      },
      "source": [
        "### Experiment: Dyna-Q+ agent in the _changing_ environment\n",
        "\n",
        "Okay, now we're ready to test our Dyna-Q+ agent on the Shortcut Maze. As usual, we will average the results over 30 independent runs of the experiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxj6UesTAMtA",
        "outputId": "f8516df5-5de4-4baa-ec50-502a234a8f93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Do NOT modify the parameter settings.\n",
        "\n",
        "# Experiment parameters\n",
        "experiment_parameters = {\n",
        "    \"num_runs\" : 30,                     # The number of times we run the experiment\n",
        "    \"num_max_steps\" : 6000,              # The number of steps per experiment\n",
        "}\n",
        "\n",
        "# Environment parameters\n",
        "environment_parameters = { \n",
        "    \"discount\": 0.95,\n",
        "    \"change_at_n\": 3000\n",
        "}\n",
        "\n",
        "# Agent parameters\n",
        "agent_parameters = {  \n",
        "    \"num_states\" : 54,\n",
        "    \"num_actions\" : 4, \n",
        "    \"epsilon\": 0.1, \n",
        "    \"step_size\" : 0.5,\n",
        "    \"planning_steps\" : [50]      \n",
        "}\n",
        "\n",
        "current_env = ShortcutMazeEnvironment   # The environment\n",
        "current_agent = DynaQPlusAgent          # The agent\n",
        "\n",
        "run_experiment_with_state_visitations(current_env, current_agent, environment_parameters, agent_parameters, experiment_parameters, \"Dyna-Q+\")\n",
        "shutil.make_archive('results', 'zip', 'results');"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Planning steps :  50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
            "  3%|▎         | 1/30 [00:14<06:55, 14.32s/it]\u001b[A\n",
            "  7%|▋         | 2/30 [00:30<06:55, 14.82s/it]\u001b[A\n",
            " 10%|█         | 3/30 [00:45<06:40, 14.83s/it]\u001b[A\n",
            " 13%|█▎        | 4/30 [00:59<06:22, 14.73s/it]\u001b[A\n",
            " 17%|█▋        | 5/30 [01:14<06:12, 14.91s/it]\u001b[A\n",
            " 20%|██        | 6/30 [01:29<05:54, 14.79s/it]\u001b[A\n",
            " 23%|██▎       | 7/30 [01:43<05:37, 14.67s/it]\u001b[A\n",
            " 27%|██▋       | 8/30 [01:59<05:27, 14.90s/it]\u001b[A\n",
            " 30%|███       | 9/30 [02:14<05:11, 14.84s/it]\u001b[A\n",
            " 33%|███▎      | 10/30 [02:28<04:56, 14.84s/it]\u001b[A\n",
            " 37%|███▋      | 11/30 [02:44<04:47, 15.14s/it]\u001b[A\n",
            " 40%|████      | 12/30 [02:59<04:29, 14.98s/it]\u001b[A\n",
            " 43%|████▎     | 13/30 [03:15<04:18, 15.22s/it]\u001b[A\n",
            " 47%|████▋     | 14/30 [03:30<04:02, 15.18s/it]\u001b[A\n",
            " 50%|█████     | 15/30 [03:45<03:46, 15.13s/it]\u001b[A\n",
            " 53%|█████▎    | 16/30 [04:00<03:31, 15.11s/it]\u001b[A\n",
            " 57%|█████▋    | 17/30 [04:14<03:14, 14.99s/it]\u001b[A\n",
            " 60%|██████    | 18/30 [04:29<02:58, 14.86s/it]\u001b[A\n",
            " 63%|██████▎   | 19/30 [04:44<02:45, 15.02s/it]\u001b[A\n",
            " 67%|██████▋   | 20/30 [04:59<02:30, 15.00s/it]\u001b[A\n",
            " 70%|███████   | 21/30 [05:15<02:16, 15.17s/it]\u001b[A\n",
            " 73%|███████▎  | 22/30 [05:31<02:02, 15.33s/it]\u001b[A\n",
            " 77%|███████▋  | 23/30 [05:46<01:46, 15.26s/it]\u001b[A\n",
            " 80%|████████  | 24/30 [06:00<01:30, 15.02s/it]\u001b[A\n",
            " 83%|████████▎ | 25/30 [06:14<01:13, 14.74s/it]\u001b[A\n",
            " 87%|████████▋ | 26/30 [06:30<00:59, 14.98s/it]\u001b[A\n",
            " 90%|█████████ | 27/30 [06:45<00:45, 15.17s/it]\u001b[A\n",
            " 93%|█████████▎| 28/30 [07:00<00:29, 14.94s/it]\u001b[A\n",
            " 97%|█████████▋| 29/30 [07:15<00:15, 15.05s/it]\u001b[A\n",
            "100%|██████████| 30/30 [07:30<00:00, 15.02s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "0aae91605b0be56ef43e821b1719bfbf",
          "grade": false,
          "grade_id": "cell-d1f8fd21d4357f1a",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "sYJVXah9AMtA"
      },
      "source": [
        "Let's compare the Dyna-Q and Dyna-Q+ agents with `planning_steps=50` each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "d35e2a4111ca0d5f4baf83885e537139",
          "grade": false,
          "grade_id": "cell-ceee2185289f571c",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "nbmf3fsNAMtA"
      },
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "def plot_cumulative_reward_comparison(file_name_dynaq, file_name_dynaqplus):\n",
        "\n",
        "    cum_reward_q = np.load(file_name_dynaq,allow_pickle=True).item()['cum_reward_all'][2]\n",
        "    cum_reward_qPlus = np.load(file_name_dynaqplus,allow_pickle=True).item()['cum_reward_all'][0]\n",
        "\n",
        "    plt.plot(np.mean(cum_reward_qPlus, axis=0), label='Dyna-Q+')\n",
        "    plt.plot(np.mean(cum_reward_q, axis=0), label='Dyna-Q')\n",
        "\n",
        "    plt.axvline(x=3000, linestyle='--', color='grey', alpha=0.4)\n",
        "    plt.xlabel('Timesteps')\n",
        "    plt.ylabel('Cumulative\\nreward', rotation=0, labelpad=60)\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.title('Average performance of Dyna-Q and Dyna-Q+ agents in the Shortcut Maze\\n')\n",
        "    plt.show()"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AZOaMQ_AMtA",
        "outputId": "1995eb88-25cc-416c-b31c-fd2cf0b990ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "plot_cumulative_reward_comparison('results/Dyna-Q_shortcut_steps.npy', 'results/Dyna-Q+.npy')"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "21076543e2048b8680e6e0aef7fe3eb8",
          "grade": false,
          "grade_id": "cell-1754be7eabd4a8aa",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "L4t8WQhQAMtB"
      },
      "source": [
        "What do you observe? (For reference, your graph should look like [Figure 8.5 in Chapter 8](http://www.incompleteideas.net/book/RLbook2018.pdf#page=189) of the RL textbook)\n",
        "\n",
        "The slope of the curve increases for the Dyna-Q+ curve shortly after the shortcut opens up after 3000 steps, which indicates that the rate of receiving the positive reward increases. This implies that the Dyna-Q+ agent finds the shorter path to the goal.\n",
        "\n",
        "To verify this, let us plot the state-visitations of the Dyna-Q+ agent before and after the shortcut opens up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ma3jrl1AMtB",
        "outputId": "126cc7c5-31a5-4a77-b0f3-9e74f3f16c7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "plot_state_visitations(\"results/Dyna-Q+.npy\", ['Dyna-Q+ : State visitations before the env changes', 'Dyna-Q+ : State visitations after the env changes'], 0)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "449ce5338414248561fc1c8219cc3792",
          "grade": false,
          "grade_id": "cell-fafb7f5a25d136fb",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "e5Pg9JW1AMtB"
      },
      "source": [
        "What do you observe?\n",
        "\n",
        "Before the shortcut opens up, like Dyna-Q, the Dyna-Q+ agent finds the sole, long path to the goal. But because the Dyna-Q+ agent keeps exploring, it succeeds in discovering the shortcut once it opens up, which leads to the goal faster. So the bonus reward heuristic is effective in helping the agent explore and find changes in the environment without degrading the performance. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "29cd9402feeb69c6d64d8ae08c9aa201",
          "grade": false,
          "grade_id": "cell-89485f6ff67b4a48",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "K3b1mxWUAMtC"
      },
      "source": [
        "## Wrapping Up\n",
        "\n",
        "Congratulations! You have:\n",
        "\n",
        "1. implemented Dyna-Q, a model-based approach to RL;\n",
        "2. implemented Dyna-Q+, a variant of Dyna-Q with an exploration bonus that encourages exploration; \n",
        "3. conducted scientific experiments to empirically validate the exploration/exploitation dilemma in the planning context on an environment that changes with time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "bdccc04273c6aadc27991c28fb2065e9",
          "grade": false,
          "grade_id": "cell-5ff77de3e5722637",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "BeksDCZXAMtC"
      },
      "source": [
        "Some points to ponder about:\n",
        "1. At what cost does Dyna-Q+ improve over Dyna-Q?\n",
        "2. In general, what is the trade-off of using model-based methods like Dyna-Q over model-free methods like Q-learning?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Note**: Apart from using the 'Submit' button in the notebook, you have to submit an additional `zip` file containing the 'npy' files that were generated from running the experiment cells. To do so:\n",
        "\n",
        "1. Generate the zip file by running the experiment cells in the notebook. On the top of the notebook, navigate to 'File->Open' to open the directory view of this assignment. Select \"results.zip\" and click on \"Download\". Alternatively, you can download just the results folder and run \"zip -jr results.zip results/\" (_The flag 'j' is required by the grader!_).\n",
        "2. Go to the \"My submission\" tab and click on \"+ Create submission\".\n",
        "3. Click on \"C2M4 Data-file Grader\" and upload your `results.zip`.\n",
        "\n",
        "**This accounts for 50% of the marks, so don't forget to do so!**"
      ]
    }
  ]
}